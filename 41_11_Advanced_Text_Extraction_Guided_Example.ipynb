{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "41.11  Advanced Text Extraction - Guided Example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or9Lvp__LY0p",
        "colab_type": "text"
      },
      "source": [
        "# Drill\n",
        "\n",
        "Take the well-known 20 newsgroups dataset and use each of the methods on it. Your goal is to determine which method, if any, best reproduces the topics represented by the newsgroups. Write up a report where you evaluate each method in light of the 'ground truth'- the known source of each newsgroup post. Which works best, and why do you think this is the case?\n",
        "\n",
        "### Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHgh10jRLgRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avloLpy6LklZ",
        "colab_type": "text"
      },
      "source": [
        "### 20 Newsgroups Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfjftVbdLm45",
        "colab_type": "code",
        "outputId": "19286112-b828-42b8-c007-493f8e037d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups = fetch_20newsgroups()\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(list(newsgroups.target_names))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism',\n",
            " 'comp.graphics',\n",
            " 'comp.os.ms-windows.misc',\n",
            " 'comp.sys.ibm.pc.hardware',\n",
            " 'comp.sys.mac.hardware',\n",
            " 'comp.windows.x',\n",
            " 'misc.forsale',\n",
            " 'rec.autos',\n",
            " 'rec.motorcycles',\n",
            " 'rec.sport.baseball',\n",
            " 'rec.sport.hockey',\n",
            " 'sci.crypt',\n",
            " 'sci.electronics',\n",
            " 'sci.med',\n",
            " 'sci.space',\n",
            " 'soc.religion.christian',\n",
            " 'talk.politics.guns',\n",
            " 'talk.politics.mideast',\n",
            " 'talk.politics.misc',\n",
            " 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnckR6bmL5cJ",
        "colab_type": "text"
      },
      "source": [
        "### Generating the tf-idf Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_sC1CnvLgu5",
        "colab_type": "code",
        "outputId": "1d113db4-8d2a-4906-de4e-ab4ffa65cfa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Processing the data.\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "\n",
        "#reading in the data, this time in the form of paragraphs\n",
        "#from sklearn.datasets import fetch_20newsgroups\n",
        "#newsgroups = fetch_20newsgroups()\n",
        "\n",
        "#processing\n",
        "newsgroups_paras=[]\n",
        "for paragraph in list(newsgroups.target_names):\n",
        "   para=paragraph#[0]\n",
        "   print ('para', para)\n",
        "   #removing the double-dash from all words\n",
        "   para=[re.sub(r'--','',word) for word in para]\n",
        "   #Forming each paragraph into a string and adding it to the list of strings.\n",
        "   newsgroups_paras.append(''.join(para))\n",
        "#print newsgroups_paras\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "newsgroups_paras_tfidf=vectorizer.fit_transform(newsgroups_paras)\n",
        "#print newsgroups_paras_tfidf\n",
        "\n",
        "\n",
        "# Creating the tf-idf matrix.\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "newsgroups_paras_tfidf=vectorizer.fit_transform(newsgroups_paras)\n",
        "\n",
        "# Getting the word list.\n",
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "# Number of topics.\n",
        "ntopics=5\n",
        "\n",
        "# Linking words to topics\n",
        "def word_topic(tfidf, solution, wordlist):\n",
        "    \n",
        "    # Loading scores for each word on each topic/component.\n",
        "    words_by_topic=tfidf.T * solution\n",
        "\n",
        "    # Linking the loadings to the words in an easy-to-read way.\n",
        "    components=pd.DataFrame(words_by_topic,index=wordlist)\n",
        "    \n",
        "    return components\n",
        "\n",
        "# Extracts the top N words and their loadings for each topic.\n",
        "def top_words(components, n_top_words):\n",
        "    n_topics = range(components.shape[1])\n",
        "    index= np.repeat(n_topics, n_top_words, axis=0)\n",
        "    topwords=pd.Series(index=index)\n",
        "    for column in range(components.shape[1]):\n",
        "        # Sort the column so that highest loadings are at the top.\n",
        "        sortedwords=components.iloc[:,column].sort_values(ascending=False)\n",
        "        # Choose the N highest loadings.\n",
        "        chosen=sortedwords[:n_top_words]\n",
        "        # Combine loading and index into a string.\n",
        "        chosenlist=chosen.index +\" \"+round(chosen,2).map(str) \n",
        "        topwords.loc[column]=chosenlist\n",
        "    return(topwords)\n",
        "\n",
        "# Number of words to look at for each topic.\n",
        "n_top_words = 10"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "para alt.atheism\n",
            "para comp.graphics\n",
            "para comp.os.ms-windows.misc\n",
            "para comp.sys.ibm.pc.hardware\n",
            "para comp.sys.mac.hardware\n",
            "para comp.windows.x\n",
            "para misc.forsale\n",
            "para rec.autos\n",
            "para rec.motorcycles\n",
            "para rec.sport.baseball\n",
            "para rec.sport.hockey\n",
            "para sci.crypt\n",
            "para sci.electronics\n",
            "para sci.med\n",
            "para sci.space\n",
            "para soc.religion.christian\n",
            "para talk.politics.guns\n",
            "para talk.politics.mideast\n",
            "para talk.politics.misc\n",
            "para talk.religion.misc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYJBayfQx48r",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the Three Topic Extraction Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CngQTxJhMReI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSA\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "svd= TruncatedSVD(ntopics)\n",
        "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
        "newsgroups_paras_lsa = lsa.fit_transform(newsgroups_paras_tfidf)\n",
        "\n",
        "components_lsa = word_topic(newsgroups_paras_tfidf, newsgroups_paras_lsa, terms)\n",
        "\n",
        "topwords=pd.DataFrame()\n",
        "topwords['LSA']=top_words(components_lsa, n_top_words)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwfUloOuyFN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "0347880f-dea7-4ca5-bd43-dad521f65152"
      },
      "source": [
        "# LDA\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
        "\n",
        "lda = LDA(n_topics=ntopics, \n",
        "          doc_topic_prior=None, # Prior = 1/n_documents\n",
        "          topic_word_prior=1/ntopics,\n",
        "          learning_decay=0.7, # Convergence rate.\n",
        "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
        "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
        "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
        "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
        "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
        "          n_jobs=-1, # Use all available CPUs to speed up processing time.\n",
        "          verbose=0, # amount of output to give while iterating\n",
        "          random_state=0\n",
        "         )\n",
        "\n",
        "newsgroups_paras_lda = lda.fit_transform(newsgroups_paras_tfidf) \n",
        "\n",
        "components_lda = word_topic(newsgroups_paras_tfidf, newsgroups_paras_lda, terms)\n",
        "\n",
        "topwords['LDA']=top_words(components_lda, n_top_words)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1af0188c1096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Use all available CPUs to speed up processing time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# amount of output to give while iterating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m          )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_topics'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbMPJOfGyMo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NNMF\n",
        "\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nmf = NMF(alpha=0.0, \n",
        "          init='nndsvdar', # how starting value are calculated\n",
        "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
        "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
        "          n_components=ntopics, \n",
        "          random_state=0, \n",
        "          solver='cd', # Use Coordinate Descent to solve\n",
        "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
        "          verbose=0 # amount of output to give while iterating\n",
        "         )\n",
        "newsgroups_paras_nmf = nmf.fit_transform(newsgroups_paras_tfidf) \n",
        "\n",
        "components_nmf = word_topic(newsgroups_paras_tfidf, newsgroups_paras_nmf, terms)\n",
        "\n",
        "topwords['NNMF']=top_words(components_nmf, n_top_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci9JWxlwy0GJ",
        "colab_type": "text"
      },
      "source": [
        "### Inspecting the Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdXckHxsyo8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8d9b307-ebb3-4572-8e9b-573f5b1d3e3a"
      },
      "source": [
        "for topic in range(ntopics):\n",
        "    print('Topic {}:'.format(topic))\n",
        "    print(topwords.loc[topic])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0:\n",
            "   LSA NNMF\n",
            "0  NaN  NaN\n",
            "0  NaN  NaN\n",
            "0  NaN  NaN\n",
            "0  NaN  NaN\n",
            "0  NaN  NaN\n",
            "0  NaN  NaN\n",
            "0  NaN  NaN\n",
            "0  NaN  NaN\n",
            "0  NaN  NaN\n",
            "0  NaN  NaN\n",
            "Topic 1:\n",
            "   LSA NNMF\n",
            "1  NaN  NaN\n",
            "1  NaN  NaN\n",
            "1  NaN  NaN\n",
            "1  NaN  NaN\n",
            "1  NaN  NaN\n",
            "1  NaN  NaN\n",
            "1  NaN  NaN\n",
            "1  NaN  NaN\n",
            "1  NaN  NaN\n",
            "1  NaN  NaN\n",
            "Topic 2:\n",
            "   LSA NNMF\n",
            "2  NaN  NaN\n",
            "2  NaN  NaN\n",
            "2  NaN  NaN\n",
            "2  NaN  NaN\n",
            "2  NaN  NaN\n",
            "2  NaN  NaN\n",
            "2  NaN  NaN\n",
            "2  NaN  NaN\n",
            "2  NaN  NaN\n",
            "2  NaN  NaN\n",
            "Topic 3:\n",
            "   LSA NNMF\n",
            "3  NaN  NaN\n",
            "3  NaN  NaN\n",
            "3  NaN  NaN\n",
            "3  NaN  NaN\n",
            "3  NaN  NaN\n",
            "3  NaN  NaN\n",
            "3  NaN  NaN\n",
            "3  NaN  NaN\n",
            "3  NaN  NaN\n",
            "3  NaN  NaN\n",
            "Topic 4:\n",
            "   LSA NNMF\n",
            "4  NaN  NaN\n",
            "4  NaN  NaN\n",
            "4  NaN  NaN\n",
            "4  NaN  NaN\n",
            "4  NaN  NaN\n",
            "4  NaN  NaN\n",
            "4  NaN  NaN\n",
            "4  NaN  NaN\n",
            "4  NaN  NaN\n",
            "4  NaN  NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJA1ofZwzLdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}