{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "42_Twitter_NLP_Project (9).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a08hAOyxy648",
        "colab_type": "text"
      },
      "source": [
        "### Ideas\n",
        "\n",
        "- Look at the top words used in positive and negative tweets. You could use word clouds to show what the top words are (a bar chart's second choice). You can use the wordcloud library for this. \n",
        "\n",
        "1.   Towards Data Science, [\"A Complete Exploratory Data Analysis and Visualization for Text Data\"](https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a)\n",
        "2.   YouTube, [Natural Language Processing (Part 2): Data Cleaning & Text Pre-Processing in Python](https://www.youtube.com/watch?v=iQ1bfDMCv_c), see 20:22 for code on text cleaning in cell 19.\n",
        "3. Keep watching the series at this link: https://www.youtube.com/watch?v=N9CT6Ggh0oE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7SfG58xDWfh",
        "colab_type": "text"
      },
      "source": [
        "# Twitter NLP Project\n",
        "\n",
        "The purpose of this project is to: \n",
        "\n",
        "1. Use NLP to analyze customer support tweets on Twitter to classify the sentiment of the tweets as negative or positive. \n",
        "2. And use clustering to look for patterns among consumers and and the companies and gain insights from that information. \n",
        "\n",
        "Why this is valuable: \n",
        "\n",
        "For a company that currently uses Twitter for customer support, this could help them get a deeper understanding of their customer service interactions.\n",
        "\n",
        "In the case of companies that arenâ€™t using Twitter, but are considering it, this would help them build a customer service strategy by giving them a better sense of how other brands provide service and which brands have the most positive interactions with their customers.\n",
        "\n",
        "Further, while many consumers still use traditional customer service avenues, like speaking to customer support over the phone, one-third of millennials use social media to connect with brands. And as more digital natives are born, that trend will likely continue and make customer service provided on social media increasingly important. ([Steinmetz](https://time.com/4894182/twitter-company-complaints/))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9onm-sZwPyWY",
        "colab_type": "text"
      },
      "source": [
        "### Table of Contents\n",
        "\n",
        "1. Import Statements.\n",
        "2. Importing the Dataset. \n",
        "3. Exploratory Data Analysis (EDA).\n",
        "4. Analyzing the Data with NLP Techniques.\n",
        "5. Using Clustering to Draw Insights.\n",
        "6. Key Takeaways.\n",
        "7. Next Steps.\n",
        "8. Resources.\n",
        "9. Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOgF0HzwE_Bq",
        "colab_type": "text"
      },
      "source": [
        "### 1. Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzoinTeTqqt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuc6mDStFBih",
        "colab_type": "text"
      },
      "source": [
        "### 2. Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zkqq4A8q1V_",
        "colab_type": "code",
        "outputId": "ce636365-8f84-433b-f4d3-bc3f496e1103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIz6dNnTrcg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/Datasets for Data Science Projects/twcs.csv'\n",
        "twitter_df = pd.read_csv(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3_XcMHqGhOK",
        "colab_type": "text"
      },
      "source": [
        "### 3. Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l87BwOCGlf6",
        "colab_type": "text"
      },
      "source": [
        "Because this is a new data set, it'll be helpful to use EDA to get a feel for the data, add features, clean it up and explore the data with visuals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jubHmdyLigU",
        "colab_type": "text"
      },
      "source": [
        "*Looking at the Dataframe*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOmsiPkKFFSx",
        "colab_type": "code",
        "outputId": "e8acc0b8-f92f-4261-fe97-ce54c178f480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "twitter_df.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id   author_id  ...  response_tweet_id in_response_to_tweet_id\n",
              "0         1  sprintcare  ...                  2                     3.0\n",
              "1         2      115712  ...                NaN                     1.0\n",
              "2         3      115712  ...                  1                     4.0\n",
              "3         4  sprintcare  ...                  3                     5.0\n",
              "4         5      115712  ...                  4                     6.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abd7D69iLK8u",
        "colab_type": "code",
        "outputId": "e6b13ddb-d5ba-4d04-80ac-7181f52a899d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "twitter_df['author_id'].nunique()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "702777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSWr8t7hho91",
        "colab_type": "code",
        "outputId": "40188252-09e6-4f4b-e0b6-2c8f7143488d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(twitter_df['created_at'].min())\n",
        "print(twitter_df['created_at'].max())"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 01 17:37:48 +0000 2016\n",
            "Wed Sep 28 18:06:15 +0000 2016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u4Ub17tHFgS",
        "colab_type": "text"
      },
      "source": [
        "Intial observations from looking at the dataframe: \n",
        "\n",
        "- The dataset's 2,811,774 rows by seven columns, which is large. \n",
        "- There are 702,777 unique authors in this dataset and there are an average of four tweets/author.\n",
        "- The tweets are from the beginning of April through late September in 2016."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8JuC1edVE5V",
        "colab_type": "text"
      },
      "source": [
        "*3.2 Feature Engineering*\n",
        "\n",
        "I'd like to add features related to the companies, like which industries they belong to, and I'll work on that in that in this section.\n",
        "\n",
        "To get started, I need to isolate the values in the *author_id* column so that it only includes the names of companies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAO1bU0yVZr-",
        "colab_type": "code",
        "outputId": "e701fe79-6fa7-4b79-822a-c0ce384bf7e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# I'll make a new dataframe to keep track of the changes that I'm making.\n",
        "authors_df = twitter_df.copy()\n",
        "\n",
        "# I'll also make a new variable, called author_alphas, and add it to the authors_dataframe. \n",
        "# This variable will show which variables are alphabetic. And since individuals are represented by numbers, this will tell us which author_ids are companies and which aren't.\n",
        "authors_df['author_alphas'] = authors_df['author_id'].str.isalpha()\n",
        "\n",
        "print(authors_df['author_alphas'])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0           True\n",
            "1          False\n",
            "2          False\n",
            "3           True\n",
            "4          False\n",
            "           ...  \n",
            "2811769     True\n",
            "2811770    False\n",
            "2811771    False\n",
            "2811772     True\n",
            "2811773    False\n",
            "Name: author_alphas, Length: 2811774, dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk3Hioprd0Ub",
        "colab_type": "code",
        "outputId": "eadda918-60a4-4873-d8f2-1aeb3c135338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# I'll make another variable, called 'author_is_company', to help me drop the individuals from the dataframe.\n",
        "author_is_individual = authors_df[authors_df['author_alphas'] == False].index\n",
        "\n",
        "authors_df.drop(author_is_individual, inplace=True)\n",
        "\n",
        "authors_df.head()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "      <th>author_alphas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
              "      <td>@115712 Can you please send us a private messa...</td>\n",
              "      <td>5,7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:35 +0000 2017</td>\n",
              "      <td>@115713 This is saddening to hear. Please shoo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 20:03:31 +0000 2017</td>\n",
              "      <td>@115713 We understand your concerns and we'd l...</td>\n",
              "      <td>12</td>\n",
              "      <td>16.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id   author_id  ...  in_response_to_tweet_id author_alphas\n",
              "0         1  sprintcare  ...                      3.0          True\n",
              "3         4  sprintcare  ...                      5.0          True\n",
              "5         6  sprintcare  ...                      8.0          True\n",
              "7        11  sprintcare  ...                     12.0          True\n",
              "9        15  sprintcare  ...                     16.0          True\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D6nZRqkLb7i",
        "colab_type": "code",
        "outputId": "f0884fc4-8c6c-4099-e7a7-8a88c2a4ca6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# From looking at the dataframe, my sense is that the table only has companies listed, but I'll double-check that by looking at the values in that column. \n",
        "authors_df['author_alphas'].unique()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9H37LwflLi",
        "colab_type": "text"
      },
      "source": [
        "Now that the *author_id* column only has companies listed, I'm closer to being able to do feature engineering with the company information. But there's still more to do, like getting a list of all the company names and seeing how many companies there are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkPazCKhfkfL",
        "colab_type": "code",
        "outputId": "24ebc87e-e1b3-4088-dfc3-62ef0f48da60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# This will give me the list of company names.\n",
        "authors_df['author_id'].unique()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sprintcare', 'VerizonSupport', 'ChipotleTweets', 'AskPlayStation',\n",
              "       'marksandspencer', 'MicrosoftHelps', 'ATVIAssist', 'AdobeCare',\n",
              "       'AmazonHelp', 'XboxSupport', 'AirbnbHelp', 'nationalrailenq',\n",
              "       'AirAsiaSupport', 'Morrisons', 'NikeSupport', 'AskAmex',\n",
              "       'McDonalds', 'YahooCare', 'AskLyft', 'UPSHelp', 'Delta',\n",
              "       'AppleSupport', 'Tesco', 'SpotifyCares', 'comcastcares',\n",
              "       'AmericanAir', 'TMobileHelp', 'VirginTrains', 'SouthwestAir',\n",
              "       'AskeBay', 'GWRHelp', 'sainsburys', 'AskPayPal', 'HPSupport',\n",
              "       'ChaseSupport', 'CoxHelp', 'DropboxSupport', 'VirginAtlantic',\n",
              "       'AzureSupport', 'AlaskaAir', 'ArgosHelpers', 'AskTarget',\n",
              "       'GoDaddyHelp', 'CenturyLinkHelp', 'AskPapaJohns', 'askpanera',\n",
              "       'Walmart', 'USCellularCares', 'AsurionCares', 'GloCare',\n",
              "       'NeweggService', 'VirginAmerica', 'DunkinDonuts', 'TfL',\n",
              "       'asksalesforce', 'Kimpton', 'AskCiti', 'IHGService',\n",
              "       'LondonMidland', 'JetBlue', 'BoostCare', 'JackBox', 'AldiUK',\n",
              "       'HiltonHelp', 'GooglePlayMusic', 'OfficeSupport', 'DellCares',\n",
              "       'TwitterSupport', 'GreggsOfficial', 'ATT', 'TacoBellTeam',\n",
              "       'AskRBC', 'ArbysCares', 'NortonSupport', 'AskSeagate',\n",
              "       'sizehelpteam', 'SCsupport', 'MOO', 'AskDSC', 'AskVirginMoney',\n",
              "       'AskRobinhood', 'AWSSupport', 'VMUcare', 'mediatemplehelp',\n",
              "       'AskTigogh', 'PandoraSupport', 'askvisa', 'OPPOCareIN',\n",
              "       'PearsonSupport', 'CarlsJr', 'HotelTonightCX'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1xjZeWzkFSa",
        "colab_type": "code",
        "outputId": "f8658a1e-d6e2-4477-f36d-afd3fb189ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "authors_df['author_id'].nunique()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYeXZpZmLuPZ",
        "colab_type": "text"
      },
      "source": [
        "I'll use feature engineering to add these variables to the dataframe by building off the list of company names: \n",
        "\n",
        "1. Industry.\n",
        "  - This will list which sector each company's in. This includes banks, retail, restaurants and so on.\n",
        "  - To get the sector information, I went to the US Chamber of Commerce and saw that on their [frequently asked questions page](https://www.uschamber.com/about/about-the-us-chamber/frequently-asked-questions#3) they recommend using [Salesgenie](https://www.salesgenie.com/) to research how companies are classified. From there, I made a Salesgenie profile and used their free, three-day trial to gather data.\n",
        "  - Note: Salesgenie only has information on US companies, but some of the companies in the dataset were from other countries. In those cases, I assigned sectors to companies based off how their American counter-parts had been classified. For instance, I listed the Royal Bank of Canada as a bank because Citibank is also listed as a bank.\n",
        "  - For a full list of non-US companies and the industries they were assigned to, please reference the Appendix.\n",
        "\n",
        "2. NASDAQ Listing.\n",
        "  - Please note that: \n",
        "  1. The NASDAQ information was gathered from [Yahoo! Finance](https://finance.yahoo.com/). For your reference, here's an example of a search where I took the [Adjusted Close Number for Adobe's stock from May 31, 2016](https://finance.yahoo.com/quote/ADBE/history?period1=1462078800&period2=1464757200&interval=1mo&filter=history&frequency=1mo).\n",
        "  2. Some companies that are listed on NASDAQ now, like Uber, weren't listed on the exchange in 2016 because they hadn't gone public yet. \n",
        "  3. In some cases a company's not listed on NASDAQ because it's privately held and may never go public.\n",
        "\n",
        "3. NASDAQ Price (in USD).\n",
        "  - If a company was listed on NASDAQ on May 31, 2016 this will show the adjusted value of how much the stock cost on that day.\n",
        "\n",
        "4. Major Event.\n",
        "  - If a company experienced an event that impacted thousands of people, such as a service outtage, and the event was covered by multiple news sources I recorded that and assigned it a value of one; however, if a company didn't have a major event, it was given a zero.\n",
        "  - For your reference, [here's an example of a search]((https://www.google.com/search?biw=1920&bih=969&tbs=cdr%3A1%2Ccd_min%3A4%2F1%2F2016%2Ccd_max%3A9%2F28%2F2016&tbm=nws&ei=MznTXcm0Eoi8tgWlqqZY&q=london+midland&oq=london+midland&gs_l=psy-ab.3..0l2.39991.41189.0.41514.14.11.0.3.3.0.165.1405.3j8.11.0....0...1c.1.64.psy-ab..1.13.1263...0i131k1.0.X-aRa17UL9k) where I found information about a train derailment that impacted London Midland's services. In the 'major_event' column, I said that a, \"train derailment caused disruption in service\".\n",
        "\n",
        "5. Event Month.\n",
        "  - Because the dataframe covers April 1st through September 28th, I looked for events that occurred during that timeframe and noted the month as a number. For instance, April was four and May was five. In cases where there wasn't a major event, I put down a zero.\n",
        "\n",
        "6. Event Highlights.\n",
        "  - To provide insights, I wrote down a highlight about event.\n",
        "\n",
        "7. Company.\n",
        "  - To make it easier to tell companies and individuals apart, I'll add a column to show if the author of a tweet is a company or an individual. If the author's a company, they'll get assigned a value of one. If it's an individual, the value will be zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbvN147_fiQ7",
        "colab_type": "text"
      },
      "source": [
        "Adding the new features to the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mqjsBCQjOEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I'll make a new dataframe for the feature engineering.\n",
        "regex_df = twitter_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ufw-gY-1dnS",
        "colab_type": "code",
        "outputId": "a6909c8a-07ce-4b05-a8bb-afdaf0284f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "list1 = []\n",
        "\n",
        "for i in regex_df['author_id']:\n",
        " try:\n",
        "   i = float(i)\n",
        " except:\n",
        "   pass\n",
        " if type(i) in [int, float]:\n",
        "   list1.append('non-company')\n",
        " else:\n",
        "   list1.append(i)\n",
        "\n",
        "#print list1\n",
        "regex_df['new_column'] = list1\n",
        "print(regex_df)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         tweet_id   author_id  ...  in_response_to_tweet_id   new_column\n",
            "0               1  sprintcare  ...                      3.0   sprintcare\n",
            "1               2      115712  ...                      1.0  non-company\n",
            "2               3      115712  ...                      4.0  non-company\n",
            "3               4  sprintcare  ...                      5.0   sprintcare\n",
            "4               5      115712  ...                      6.0  non-company\n",
            "...           ...         ...  ...                      ...          ...\n",
            "2811769   2987947  sprintcare  ...                2987948.0   sprintcare\n",
            "2811770   2987948      823869  ...                      NaN  non-company\n",
            "2811771   2812240      121673  ...                2812239.0  non-company\n",
            "2811772   2987949      AldiUK  ...                2987950.0       AldiUK\n",
            "2811773   2987950      823870  ...                      NaN  non-company\n",
            "\n",
            "[2811774 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBjXbx64ml0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I'll drop the 'author_id' column since 'new_column' has been added.\n",
        "regex_df = regex_df[['tweet_id', 'inbound', 'created_at', 'text', 'response_tweet_id', 'in_response_to_tweet_id', 'new_column']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHGVEMgZmlGj",
        "colab_type": "code",
        "outputId": "13d5d3bd-8642-4cd8-ef86-45950fec7bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Renaming 'new_column' as 'author_id'.\n",
        "regex_df = regex_df.rename(columns={'new_column': 'author_id'})\n",
        "regex_df.head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>sprintcare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>non-company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>non-company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>sprintcare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "      <td>non-company</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id  inbound  ... in_response_to_tweet_id    author_id\n",
              "0         1    False  ...                     3.0   sprintcare\n",
              "1         2     True  ...                     1.0  non-company\n",
              "2         3     True  ...                     4.0  non-company\n",
              "3         4    False  ...                     5.0   sprintcare\n",
              "4         5     True  ...                     6.0  non-company\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txaf5PrcT_Gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the 'companies_df' from Google Drive.\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Industry List Spreadsheet.xlsx'\n",
        "companies_df = pd.read_excel(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwBZDIGMM5lr",
        "colab_type": "code",
        "outputId": "bf82a5d9-bbc6-4777-a8dc-0f7cb36d36d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "companies_df.head()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author_id</th>\n",
              "      <th>industry</th>\n",
              "      <th>company</th>\n",
              "      <th>nasdaq_listing</th>\n",
              "      <th>nasdaq_price</th>\n",
              "      <th>major_event</th>\n",
              "      <th>event_month</th>\n",
              "      <th>event_highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdobeCare</td>\n",
              "      <td>Computer - Software Developers</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>95.79</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Launched new service.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AirAsiaSupport</td>\n",
              "      <td>Airline Companies</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AirbnbHelp</td>\n",
              "      <td>Marketing Consultants</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>22.68</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>Adopted anti-discrimination policies.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AlaskaAir</td>\n",
              "      <td>Airline Companies</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>54.74</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Bought Virgin America.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AldiUK</td>\n",
              "      <td>Grocers - Retail</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        author_id  ...                       event_highlights\n",
              "0       AdobeCare  ...                  Launched new service.\n",
              "1  AirAsiaSupport  ...                                    NaN\n",
              "2      AirbnbHelp  ...  Adopted anti-discrimination policies.\n",
              "3       AlaskaAir  ...                 Bought Virgin America.\n",
              "4          AldiUK  ...                                    NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26I8OJWxeqdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merging the 'regex_df' and 'companies_df' dataframes.\n",
        "regex_df = regex_df.merge(companies_df, on='author_id', how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13jm0SFKer7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "114a0a5e-f33f-4c60-a9fa-9d114e7e3968"
      },
      "source": [
        "regex_df.head()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>industry</th>\n",
              "      <th>company</th>\n",
              "      <th>nasdaq_listing</th>\n",
              "      <th>nasdaq_price</th>\n",
              "      <th>major_event</th>\n",
              "      <th>event_month</th>\n",
              "      <th>event_highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>Cellular Telephones (Services)</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.53</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>non-company</td>\n",
              "      <td>non-company</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>non-company</td>\n",
              "      <td>non-company</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>Cellular Telephones (Services)</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.53</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "      <td>non-company</td>\n",
              "      <td>non-company</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id  inbound  ... event_month event_highlights\n",
              "0         1    False  ...         0.0              NaN\n",
              "1         2     True  ...         0.0              NaN\n",
              "2         3     True  ...         0.0              NaN\n",
              "3         4    False  ...         0.0              NaN\n",
              "4         5     True  ...         0.0              NaN\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZflxxrjPe3UW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ba48abb7-dc0f-45fa-c0c8-2d5d4a4bc482"
      },
      "source": [
        "# I'll compare the shape of the original and new dataframes to make sure nothing was lost.\n",
        "print(twitter_df.shape)\n",
        "print(regex_df.shape)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2811774, 7)\n",
            "(2811774, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYSMRkiC4Apv",
        "colab_type": "text"
      },
      "source": [
        "*3.3 Data Cleaning*\n",
        "\n",
        "This dataframe has string and integer data that needs to be cleaned, so a couple of different approaches will be needed for this step. To get this step started, I'll make a new dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qCs8qtGrQm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df = regex_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-YtaQBWMuCA",
        "colab_type": "text"
      },
      "source": [
        "*Cleaning the Numbers Data*\n",
        "\n",
        "The values in these columns need to be cleaned:\n",
        "\n",
        "* 'nasdaq_listing.'\n",
        "* 'nasdaq_price.'\n",
        "* 'major_event.'\n",
        "* 'event_month.'\n",
        "* 'company.'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt9HfI6kigpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The numbers columns can be cleaned with the same method, so I'll define a function for this step.\n",
        "def clean_numbers(string, int):\n",
        "    clean_df.loc[(clean_df[string] != int), string] = 0\n",
        "    return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsCIxUMLqnm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning 'nasdaq_listing'.\n",
        "clean_numbers('nasdaq_listing', 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK51TjWgwNw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning the 'nasdaq_price'.\n",
        "clean_numbers('nasdaq_price', 4-1146)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DycVbyhaqr9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning 'major_event'.\n",
        "clean_numbers('major_event', 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCRgkNBjwpiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning 'event_month'.\n",
        "clean_numbers('event_month', 4-9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w751NEsqyf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning 'company'.\n",
        "clean_numbers('company', 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bxdb62yrRK3",
        "colab_type": "text"
      },
      "source": [
        "*Language Parsing*\n",
        "\n",
        "With the numbers data taken care of, it's time to clean these columns:\n",
        "\n",
        "* 'text'.\n",
        "* 'industry'.\n",
        "* 'event_highlights'.\n",
        "* 'created_at'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8yJbxim57XX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUtISRNlGmGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, the columns with text need to get converted from floats to strings.\n",
        "def make_string(df, string):\n",
        "  df[string] = df[string].astype(str)\n",
        "  return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7yKioMBG811",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_string(clean_df, 'text')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMAhFzEUG9F1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_string(clean_df, 'industry')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCZRpGshG9Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_string(clean_df, 'event_highlights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zhvXvhcG9ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_string(clean_df, 'created_at')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFE74kF557Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The 'clean_text' function will: make text lowercase, remove text in the square brackets, remove punctuation and words that have numbers.\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\'\\]', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = re.sub('[â€˜â€™â€œâ€â€¦]', '', text)\n",
        "    return text\n",
        "\n",
        "round1 = lambda x: clean_text(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmYrFDUP57cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's take a look at the updated text\n",
        "clean_df['text'] = pd.DataFrame(clean_df['text'].apply(round1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GgF-Jrp6EFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df['industry'] = pd.DataFrame(clean_df['industry'].apply(round1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Beae-GDb3Y2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df['event_highlights'] = pd.DataFrame(clean_df['event_highlights'].apply(round1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_cBjbB19p8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df['created_at'] = pd.DataFrame(clean_df['created_at'].apply(round1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQRDA-pX9Wx7",
        "colab_type": "text"
      },
      "source": [
        "*Reviewing the Clean Dataframe*\n",
        "\n",
        "With the data cleaning and language parsing done, I'll look at the updated dataframe to make sure it looks right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUDZYNuw3Y5X",
        "colab_type": "code",
        "outputId": "e1a9ba44-4a69-4825-d1bd-dc71e8881f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "clean_df.head()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>industry</th>\n",
              "      <th>company</th>\n",
              "      <th>nasdaq_listing</th>\n",
              "      <th>nasdaq_price</th>\n",
              "      <th>major_event</th>\n",
              "      <th>event_month</th>\n",
              "      <th>event_highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>tue oct</td>\n",
              "      <td>i understand i would like to assist you we wo...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>cellular telephones services</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>tue oct</td>\n",
              "      <td>sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>non-company</td>\n",
              "      <td>noncompany</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>tue oct</td>\n",
              "      <td>sprintcare i have sent several private message...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>non-company</td>\n",
              "      <td>noncompany</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>tue oct</td>\n",
              "      <td>please send us a private message so that we c...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>cellular telephones services</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>tue oct</td>\n",
              "      <td>sprintcare i did</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "      <td>non-company</td>\n",
              "      <td>noncompany</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id  inbound   created_at  ... major_event event_month  event_highlights\n",
              "0         1    False  tue oct      ...         0.0         0.0               nan\n",
              "1         2     True  tue oct      ...         0.0         0.0               nan\n",
              "2         3     True  tue oct      ...         0.0         0.0               nan\n",
              "3         4    False  tue oct      ...         0.0         0.0               nan\n",
              "4         5     True  tue oct      ...         0.0         0.0               nan\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSB3d_UBemhM",
        "colab_type": "text"
      },
      "source": [
        "*Visualizing the Data*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9zEXHfWTOHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcs9WSskTOFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxbNwp6jTOCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2KDIIwddPPV",
        "colab_type": "text"
      },
      "source": [
        "### 4. Analyzing Data with Supervised NLP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sokqdwv8MRuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "7079bdd5-dcd3-48db-c9c5-4c65ecc0236a"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "!python -m spacy download en"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDTC7HEYSQnk",
        "colab_type": "text"
      },
      "source": [
        "Resource: https://towardsdatascience.com/machine-learning-text-processing-1d5a2d638958/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPRVugw4OUr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahm0oU8dOUoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr20rxd0Qc_a",
        "colab_type": "code",
        "outputId": "b1b1116e-2e71-4af3-c842-6c69f57a6b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(sentences_df)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYPUkekQQc5t",
        "colab_type": "code",
        "outputId": "fc8f8aa0-f749-49ce-9f5b-a9749e365438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjgU4lcEQc2V",
        "colab_type": "code",
        "outputId": "9c4d193a-5bcf-4907-862f-cc2d4ebf36e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Machine Learning\n",
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, sentences_df.company)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-4cb56e81f386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \"\"\"\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 2810447]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMQOwmpqQcxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1nu_cOhdz3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGzIOtPT2DdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybIHeIQ4Qs5m",
        "colab_type": "text"
      },
      "source": [
        "*Trying Another Approach to BoW Using BoW from the Function Defined Below, in the Topic Modeling Section*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXuScdA7DR0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = clean_df[['text', 'company']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6PZHA-3DZHD",
        "colab_type": "code",
        "outputId": "86206496-08e4-4536-c210-f0c15019340d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sentences.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i understand i would like to assist you we wo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sprintcare and how do you propose we do that</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sprintcare i have sent several private message...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>please send us a private message so that we c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sprintcare i did</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  company\n",
              "0   i understand i would like to assist you we wo...        1\n",
              "1       sprintcare and how do you propose we do that        0\n",
              "2  sprintcare i have sent several private message...        0\n",
              "3   please send us a private message so that we c...        1\n",
              "4                                   sprintcare i did        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qng9lVW1Acxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to create a list of the 2000 most common words.\n",
        "def bag_of_words(text):\n",
        "    \n",
        "    # Filter out punctuation and stop words.\n",
        "    allwords = [token.lemma_\n",
        "                for token in text]\n",
        "    \n",
        "    # Return the most common words.\n",
        "    return [item[0] for item in Counter(allwords).most_common(2000)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxWBKBVVAcul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates a data frame with features for each word in our common word set.\n",
        "# Each value is the count of the times the word appears in each sentence.\n",
        "\n",
        "# def bow_features(sentences, common_words):\n",
        "def bow_features(sentences):\n",
        "    \n",
        "    # Scaffold the data frame and initialize counts to zero.\n",
        "    df = pd.DataFrame()\n",
        "    df['text_sentence'] = sentences[0]\n",
        "    df['text_source'] = sentences[1]\n",
        "    \n",
        "    # Process each row, counting the occurrence of words in each sentence.\n",
        "    for i, sentence in enumerate(df['text_sentence']):\n",
        "        \n",
        "        # Convert the sentence to lemmas, then filter out punctuation,\n",
        "        # stop words, and uncommon words.\n",
        "        words = [token.lemma_\n",
        "                for token in sentence]\n",
        "        \n",
        "        # Populate the row with word counts.\n",
        "        for word in words:\n",
        "            df.loc[i, word] += 1\n",
        "        \n",
        "        # This counter is just to make sure the kernel didn't hang.\n",
        "        if i % 50 == 0:\n",
        "            print(\"Processing row {}\".format(i))\n",
        "            \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb9w6WIVAcsN",
        "colab_type": "code",
        "outputId": "cf90c98d-5336-4712-93d5-be5f7f81ea6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Set up the bags.\n",
        "twitter_words = bag_of_words(sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-e5f6da865c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtwitter_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-90-09eae163cee7>\u001b[0m in \u001b[0;36mbag_of_words\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Filter out punctuation and stop words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     allwords = [token.lemma_\n\u001b[0;32m----> 5\u001b[0;31m                 for token in text]\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Return the most common words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-09eae163cee7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Filter out punctuation and stop words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     allwords = [token.lemma_\n\u001b[0;32m----> 5\u001b[0;31m                 for token in text]\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Return the most common words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'lemma_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFppf96uAj21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izz10AwNAjzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jk94v9OAcoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AucoaURtQsSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# bow_corpus\n",
        "\n",
        "rfc = ensemble.RandomForestClassifier()\n",
        "Y = word_counts['text_source']\n",
        "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.4,\n",
        "                                                    random_state=0)\n",
        "train = rfc.fit(X_train, y_train)\n",
        "\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJyg4J32dP-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnCs4dYiQsgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBHc9WR1Qse4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWyGlw8iQscf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov209oftQsa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJAbQglWdU_U",
        "colab_type": "text"
      },
      "source": [
        "### 5. Topic Modeling (Unsupervised NLP)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBZFCgbdXJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQoaX3PW7COp",
        "colab_type": "code",
        "outputId": "5746ed26-12e3-43f7-af5a-d66966415527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgtcDuANEGHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKOee28BdXMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write a function to perform the pre processing steps on the entire dataset\n",
        "\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Tokenize and lemmatize\n",
        "def preprocess(text):\n",
        "    result=[]\n",
        "    for token in gensim.utils.simple_preprocess(text) :\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "            \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWIJTjWpDnOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# processed_text = twitter_df['text'].sample(n=50000, random_state=1)\n",
        "# print(processed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYMy0VnkDVr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_docs = []\n",
        "\n",
        "for doc in twitter_df['text'].sample(n=50000, random_state=1):\n",
        "    processed_docs.append(preprocess(doc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_l6zv56DVuh",
        "colab_type": "code",
        "outputId": "b1691c54-3ce8-4071-e30a-5ce05dabe7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(processed_docs[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['atviassist'], ['applesupport', 'iphon']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BSCI7cQDVx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary from 'processed_docs' containing the number of times a word appears \n",
        "# in the training set using gensim.corpora.Dictionary and call it 'dictionary'\n",
        "\n",
        "dictionary = gensim.corpora.Dictionary(processed_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bb8aOlSGItw",
        "colab_type": "code",
        "outputId": "724120a1-183b-49aa-cdf4-cb2236d1b514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Checking dictionary created\n",
        "\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 atviassist\n",
            "1 applesupport\n",
            "2 iphon\n",
            "3 americanair\n",
            "4 dumb\n",
            "5 know\n",
            "6 store\n",
            "7 think\n",
            "8 pain\n",
            "9 info\n",
            "10 send\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGdPt5EGbJf9",
        "colab_type": "text"
      },
      "source": [
        "- Gensim filter_extremes\n",
        "\n",
        "- filter_extremes(no_below=5, no_above=0.5, keep_n=100000)\n",
        "\n",
        "- Filter out tokens that appear in:\n",
        "- less than no_below documents (absolute number) or\n",
        "- more than no_above documents (fraction of total corpus size, not absolute number).\n",
        "- after (1) and (2), keep only the first keep_n most frequent tokens (or keep all if None)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhV5GAPPGbhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OPTIONAL STEP\n",
        "# Remove very rare and very common words:\n",
        "# - words appearing less than 15 times\n",
        "# - words appearing in more than 10% of all documents\n",
        "\n",
        "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n= 100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA6mTIFRbaFU",
        "colab_type": "text"
      },
      "source": [
        "- Gensim doc2bow\n",
        "\n",
        "- doc2bow(document)\n",
        "\n",
        "- Convert document (a list of words) into the bag-of-words format = list of (token_id, token_count) 2-tuples. Each word is assumed to be a tokenized and normalized string (either unicode or utf8-encoded). \n",
        "- No further preprocessing is done on the words in document; apply tokenization, stemming etc. before calling this method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFOMeyX3GbmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
        "# words and how many times those words appear. Save this to 'bow_corpus'\n",
        "\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g2cDRvrGybq",
        "colab_type": "code",
        "outputId": "01311c23-aeae-4491-a811-a88e95d9936d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Preview BOW for our sample preprocessed document\n",
        "\n",
        "document_num = 20\n",
        "bow_doc_x = bow_corpus[document_num]\n",
        "\n",
        "for i in range(len(bow_doc_x)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
        "                                                     dictionary[bow_doc_x[i][0]], \n",
        "                                                     bow_doc_x[i][1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 86 (\"kind\") appears 1 time.\n",
            "Word 87 (\"respons\") appears 1 time.\n",
            "Word 88 (\"uber_support\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7IxwiNTHKs0",
        "colab_type": "text"
      },
      "source": [
        "We are going for 10 topics in the document corpus.\n",
        "\n",
        "We will be running LDA using all CPU cores to parallelize and speed up model training.\n",
        "\n",
        "Some of the parameters we will be tweaking are:\n",
        "\n",
        "num_topics is the number of requested latent topics to be extracted from the training corpus.\n",
        "id2word is a mapping from word ids (integers) to words (strings). It is used to determine the vocabulary size, as well as for debugging and topic printing.\n",
        "workers is the number of extra processes to use for parallelization. Uses all available cores by default.\n",
        "alpha and eta are hyperparameters that affect sparsity of the document-topic (theta) and topic-word (lambda) distributions. We will let these be the default values for now(default value is 1/num_topics)\n",
        "\n",
        "Alpha is the per document topic distribution.\n",
        "\n",
        "High alpha: Every document has a mixture of all topics(documents appear similar to each other).\n",
        "Low alpha: Every document has a mixture of very few topics\n",
        "Eta is the per topic word distribution.\n",
        "\n",
        "High eta: Each topic has a mixture of most words(topics appear similar to each other).\n",
        "Low eta: Each topic has a mixture of few words.\n",
        "passes is the number of training passes through the corpus. For example, if the training corpus has 50,000 documents, chunksize is 10,000, passes is 2, then online training is done in 10 updates:\n",
        "\n",
        "- 1 documents 0-9,999\n",
        "- 2 documents 10,000-19,999\n",
        "- 3 documents 20,000-29,999\n",
        "- 4 documents 30,000-39,999\n",
        "- 5 documents 40,000-49,999\n",
        "- 6 documents 0-9,999\n",
        "- 7 documents 10,000-19,999\n",
        "- 8 documents 20,000-29,999\n",
        "- 9 documents 30,000-39,999\n",
        "- 10 documents 40,000-49,999"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjnovHk6G4uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LDA mono-core -- fallback code in case LdaMulticore throws an error on your machine\n",
        "# lda_model = gensim.models.LdaModel(bow_corpus, \n",
        "#                                    num_topics = 10, \n",
        "#                                    id2word = dictionary,                                    \n",
        "#                                    passes = 50)\n",
        "\n",
        "# LDA multicore \n",
        "'''\n",
        "Train your lda model using gensim.models.LdaMulticore and save it to 'lda_model'\n",
        "'''\n",
        "# TODO\n",
        "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
        "                                   num_topics = 8, \n",
        "                                   id2word = dictionary,                                    \n",
        "                                   passes = 10,\n",
        "                                   workers = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SafqekPkHD4Z",
        "colab_type": "code",
        "outputId": "b541053e-b970-41ed-87bb-2044ca262683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# For each topic, we will explore the words occuring in that topic and its relative weight\n",
        "\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.042*\"flight\" + 0.025*\"americanair\" + 0.024*\"delta\" + 0.019*\"book\" + 0.019*\"virgintrain\" + 0.017*\"southwestair\" + 0.016*\"british_airway\" + 0.015*\"hour\" + 0.014*\"time\" + 0.013*\"travel\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.055*\"send\" + 0.049*\"look\" + 0.038*\"number\" + 0.037*\"assist\" + 0.035*\"account\" + 0.034*\"address\" + 0.032*\"email\" + 0.030*\"sorri\" + 0.026*\"detail\" + 0.024*\"issu\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.026*\"devic\" + 0.023*\"know\" + 0.020*\"work\" + 0.018*\"version\" + 0.017*\"start\" + 0.015*\"gdrqu\" + 0.013*\"like\" + 0.013*\"want\" + 0.012*\"upgrad\" + 0.012*\"get\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.026*\"servic\" + 0.019*\"time\" + 0.018*\"custom\" + 0.018*\"tesco\" + 0.017*\"uber_support\" + 0.015*\"go\" + 0.014*\"issu\" + 0.013*\"work\" + 0.012*\"charg\" + 0.012*\"phone\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.032*\"store\" + 0.023*\"card\" + 0.018*\"account\" + 0.017*\"xboxsupport\" + 0.017*\"option\" + 0.015*\"onlin\" + 0.014*\"purchas\" + 0.012*\"check\" + 0.012*\"tri\" + 0.012*\"websit\"\n",
            "\n",
            "\n",
            "Topic: 5 \n",
            "Words: 0.047*\"team\" + 0.031*\"sorri\" + 0.027*\"know\" + 0.026*\"hear\" + 0.023*\"sure\" + 0.018*\"support\" + 0.018*\"feedback\" + 0.017*\"soon\" + 0.017*\"hope\" + 0.016*\"great\"\n",
            "\n",
            "\n",
            "Topic: 6 \n",
            "Words: 0.063*\"amazonhelp\" + 0.059*\"order\" + 0.027*\"deliveri\" + 0.025*\"receiv\" + 0.020*\"amazon\" + 0.020*\"delay\" + 0.018*\"train\" + 0.018*\"deliv\" + 0.017*\"packag\" + 0.015*\"sorri\"\n",
            "\n",
            "\n",
            "Topic: 7 \n",
            "Words: 0.060*\"applesupport\" + 0.040*\"updat\" + 0.025*\"iphon\" + 0.022*\"free\" + 0.020*\"phone\" + 0.019*\"spotifycar\" + 0.015*\"problem\" + 0.013*\"chipotletweet\" + 0.013*\"feel\" + 0.012*\"tri\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd3E4mGaRPE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take the top five words(ish) for each category. Using expertise, label cateogry in interesting ways, that'll be your topic name.\n",
        "# If words are too general, add them to your stop words and see what shows up.\n",
        "# Goal: It'd be nice for the top few topics to be clean and explainable.\n",
        "\n",
        "# LDA gives 1. topics that are represented. 2. for each of the documents you gave it, it'll tell you how strong it is in each of the topics. Look for the document weightings for each topic.\n",
        "# 2. Get a matrix that has a column for each topic and row for each document. Might have more than one topic that's relatively high (or there could be one).  \n",
        "# 2. Then you can look on a per company basis and see what the top topics that companies are tweeting about."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L9zb5w63tZi",
        "colab_type": "text"
      },
      "source": [
        "### 6. Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRGyuYpU3wJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiYU71viVZlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_text_df = clean_df[['text', 'company', 'author_id']].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6l8_PemYiLl",
        "colab_type": "code",
        "outputId": "ba3c5241-d2ff-4c8d-a88a-d740af8172dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_text_df['company'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4lrKXi1Y_8v",
        "colab": {}
      },
      "source": [
        "sample_text_df = sample_text_df.sample(n=50000, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on7maeS_XxLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_pol(review):\n",
        "    return TextBlob(review).sentiment.polarity\n",
        "\n",
        "sample_text_df['polarity'] = sample_text_df['text'].apply(find_pol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbOfuDv0XxQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_pol(subjectivity):\n",
        "    return TextBlob(subjectivity).sentiment.subjectivity\n",
        "\n",
        "sample_text_df['subjectivity'] = sample_text_df['text'].apply(find_pol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyJzpG2TU9aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Don't re-run LDA - need to aggregate documents according to the story you want to tell.\n",
        "# Could talk about what's happening on a company level, overall company's topics vs. non-company topics. Groupby() can be useful here, with an aggregation function like describe(), avg() or mean()."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVA2FeiRY9ss",
        "colab_type": "code",
        "outputId": "68426f4f-95c8-4764-a579-ac3a91f6b635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_text_df['company'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nYLgbijZwKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_text_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twjp1SzSXxVc",
        "colab_type": "code",
        "outputId": "98da930c-1e05-4447-9046-367e132bd409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sample_text_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>company</th>\n",
              "      <th>author_id</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2360834</th>\n",
              "      <td>atviassist pls fix hqs</td>\n",
              "      <td>0</td>\n",
              "      <td>719820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375495</th>\n",
              "      <td>applesupport iphone  with  ios</td>\n",
              "      <td>0</td>\n",
              "      <td>216966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177509</th>\n",
              "      <td>either im dumb bc i dont know how to use the a...</td>\n",
              "      <td>0</td>\n",
              "      <td>165872</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497308</th>\n",
              "      <td>its such a pain mine is doing it too</td>\n",
              "      <td>0</td>\n",
              "      <td>502403</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2179157</th>\n",
              "      <td>sorry we got it wrong could you send us a dm ...</td>\n",
              "      <td>0</td>\n",
              "      <td>KFC_UKI_Help</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text  ...  subjectivity\n",
              "2360834                            atviassist pls fix hqs   ...           0.0\n",
              "375495                      applesupport iphone  with  ios  ...           0.0\n",
              "177509   either im dumb bc i dont know how to use the a...  ...           0.5\n",
              "1497308               its such a pain mine is doing it too  ...           0.5\n",
              "2179157   sorry we got it wrong could you send us a dm ...  ...           0.8\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKA5p2npQWBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Two-dimensional scatterplot to show where each company fits on the plot.\n",
        "# What's their average on those two dimensions.\n",
        "# Some will be mildly positive, or the other end and be negative.\n",
        "# Look at example tweets that are at the high and low ranges to generalize what the scores mean."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpVKzpcGVJV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_text_df['company'] = sample_text_df['company'] != 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTVXjRTYZFlt",
        "colab_type": "code",
        "outputId": "091e269b-0eb0-4b68-ac76-d073bc88d605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_text_df['company'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv2nff9vVJmC",
        "colab_type": "code",
        "outputId": "fad98b26-97f2-4895-e368-19d2b05b265a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sample_text_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>company</th>\n",
              "      <th>author_id</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2360834</th>\n",
              "      <td>atviassist pls fix hqs</td>\n",
              "      <td>True</td>\n",
              "      <td>719820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375495</th>\n",
              "      <td>applesupport iphone  with  ios</td>\n",
              "      <td>True</td>\n",
              "      <td>216966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177509</th>\n",
              "      <td>either im dumb bc i dont know how to use the a...</td>\n",
              "      <td>True</td>\n",
              "      <td>165872</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497308</th>\n",
              "      <td>its such a pain mine is doing it too</td>\n",
              "      <td>True</td>\n",
              "      <td>502403</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2179157</th>\n",
              "      <td>sorry we got it wrong could you send us a dm ...</td>\n",
              "      <td>True</td>\n",
              "      <td>KFC_UKI_Help</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text  ...  subjectivity\n",
              "2360834                            atviassist pls fix hqs   ...           0.0\n",
              "375495                      applesupport iphone  with  ios  ...           0.0\n",
              "177509   either im dumb bc i dont know how to use the a...  ...           0.5\n",
              "1497308               its such a pain mine is doing it too  ...           0.5\n",
              "2179157   sorry we got it wrong could you send us a dm ...  ...           0.8\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhFNCJDRVJ3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJq00b6kVJiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dYsqg1HdXgs",
        "colab_type": "text"
      },
      "source": [
        "### 6. Key Takeaways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVA5DsetdZ6M",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr8cstRPdZ8r",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9jysgBCdaZU",
        "colab_type": "text"
      },
      "source": [
        "### 7. Next Steps\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PPi2khpeOZN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uEzzb8KeOc8",
        "colab_type": "text"
      },
      "source": [
        "- Use clustering to analyze patterns in the companies.\n",
        "- Look at things by industry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GQIBK3qyyVP",
        "colab_type": "text"
      },
      "source": [
        "### 8. Resources\n",
        "\n",
        "This is the list of resources that were used for this analysis:\n",
        "\n",
        "1. [Google News](https://news.google.com/?hl=en-US&gl=US&ceid=US:en).\n",
        "2. [Salesgenie.com](https://www.salesgenie.com/).\n",
        "3. [Steinmetz, Katy](https://time.com/4894182/twitter-company-complaints/). Time - Tech. \"Does Tweeting at Companies Really Work?\"\n",
        "4. [US Chamber of Commerce](https://www.uschamber.com/about/about-the-us-chamber/frequently-asked-questions#3). \"Frequently Asked Questions.\"\n",
        "5. [Yahoo! Finance](https://finance.yahoo.com/).\n",
        "\n",
        "- LDA resource: https://github.com/priya-dwivedi/Deep-Learning/blob/master/topic_modeling/LDA_Newsgroup.ipynb\n",
        "- Additional LDA resource: https://towardsdatascience.com/nlp-extracting-the-main-topics-from-your-dataset-using-lda-in-minutes-21486f5aa925\n",
        "\n",
        "- Kaggle dataset: https://www.kaggle.com/thoughtvector/customer-support-on-twitter/data\n",
        "\n",
        "- Sentiment analysis: https://github.com/adashofdata/nlp-in-python-tutorial/blob/master/3-Sentiment-Analysis.ipynb\n",
        "\n",
        "- Sentiment Polarity: https://stackabuse.com/python-for-nlp-introduction-to-the-textblob-library/\n",
        "- Sentiment Analysis from YouTube series: https://github.com/adashofdata/nlp-in-python-tutorial/blob/master/3-Sentiment-Analysis.ipynb\n",
        "\n",
        "- Uploading content to Google Colab: https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92\n",
        "\n",
        "- Machine Learning - Text Processing: https://towardsdatascience.com/machine-learning-text-processing-1d5a2d638958\n",
        "\n",
        "- Text Classification: The First Step Towards Machine Learning Mastery: https://medium.com/data-from-the-trenches/text-classification-the-first-step-toward-nlp-mastery-f5f95d525d73"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSytiR0hnA56",
        "colab_type": "text"
      },
      "source": [
        "# 9. Appendix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzrCVyq4AmBC",
        "colab_type": "text"
      },
      "source": [
        "For your reference, here's the list of non-US companies that were in the dataframe and which industry they were assigned to:\n",
        "\n",
        "1. Aldi UK, Grocers - Retail.\n",
        "2. Argos, Retail.\n",
        "3. Dollar Shave Club, Retail.\n",
        "4. Glo, Cellular Telephones (Services).\n",
        "5. Great Western Railway, Commuter & Passenger Rail Service.\n",
        "6. Greggs, Restaurants.\n",
        "7. InterContinental Hotel Group, Hotel & Motel Management.\n",
        "8. London Midland, Commuter & Passenger Rail Service.\n",
        "9. Marks and Spencer, Grocers - Retail.\n",
        "10. Morrisons, Grocers - Retail.\n",
        "11. National Rail, Commuter & Passenger Rail Service.\n",
        "12. OPPO Care India, Cellular Telephones (Services).\n",
        "13. Pearson, Education.\n",
        "14. PlayStation, Video Games - Manufacturer.\n",
        "15. Royal Bank of Canada, Banks.\n",
        "16. Sainsburys, Grocers - Retail.\n",
        "17. Size?, Retail.\n",
        "18. SoundCloud, Radio Stations & Broadcasting Companies.\n",
        "19. Spotify, Radio Stations & Broadcasting Companies.\n",
        "20. Tesco, Grocers - Retail.\n",
        "21. Tigo Ghana, Cellular Telephones (Services).\n",
        "22. Transport for London, Commuter & Passenger Rail Service.\n",
        "23. Virgin America, Airline Companies.\n",
        "24. Virgin Atlantic, Airline Companies.\n",
        "25. Virgin Mobile USA, Cellular Telephones (Services).\n",
        "26. Virgin Money, Banks.\n",
        "27. Virgin Trains, Commuter & Passenger Rail Service.\n",
        "\n"
      ]
    }
  ]
}