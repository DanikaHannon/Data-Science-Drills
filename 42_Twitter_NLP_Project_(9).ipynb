{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "42_Twitter_NLP_Project (9).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a08hAOyxy648",
        "colab_type": "text"
      },
      "source": [
        "### Ideas\n",
        "\n",
        "- Look at the top words used in positive and negative tweets. You could use word clouds to show what the top words are (a bar chart's second choice). You can use the wordcloud library for this. \n",
        "\n",
        "1.   Towards Data Science, [\"A Complete Exploratory Data Analysis and Visualization for Text Data\"](https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a)\n",
        "2.   YouTube, [Natural Language Processing (Part 2): Data Cleaning & Text Pre-Processing in Python](https://www.youtube.com/watch?v=iQ1bfDMCv_c), see 20:22 for code on text cleaning in cell 19.\n",
        "3. Keep watching the series at this link: https://www.youtube.com/watch?v=N9CT6Ggh0oE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7SfG58xDWfh",
        "colab_type": "text"
      },
      "source": [
        "# Twitter NLP Project\n",
        "\n",
        "The purpose of this project is to: \n",
        "\n",
        "1. Use NLP to analyze customer support tweets on Twitter to classify the sentiment of the tweets as negative or positive. \n",
        "2. And use clustering to look for patterns among consumers and and the companies and gain insights from that information. \n",
        "\n",
        "Why this is valuable: \n",
        "\n",
        "For a company that currently uses Twitter for customer support, this could help them get a deeper understanding of their customer service interactions.\n",
        "\n",
        "In the case of companies that aren’t using Twitter, but are considering it, this would help them build a customer service strategy by giving them a better sense of how other brands provide service and which brands have the most positive interactions with their customers.\n",
        "\n",
        "Further, while many consumers still use traditional customer service avenues, like speaking to customer support over the phone, one-third of millennials use social media to connect with brands. And as more digital natives are born, that trend will likely continue and make customer service provided on social media increasingly important. ([Steinmetz](https://time.com/4894182/twitter-company-complaints/))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9onm-sZwPyWY",
        "colab_type": "text"
      },
      "source": [
        "### Table of Contents\n",
        "\n",
        "1. Import Statements.\n",
        "2. Importing the Dataset. \n",
        "3. Exploratory Data Analysis (EDA).\n",
        "4. Analyzing the Data with NLP Techniques.\n",
        "5. Using Clustering to Draw Insights.\n",
        "6. Key Takeaways.\n",
        "7. Next Steps.\n",
        "8. Resources.\n",
        "9. Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOgF0HzwE_Bq",
        "colab_type": "text"
      },
      "source": [
        "### 1. Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzoinTeTqqt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuc6mDStFBih",
        "colab_type": "text"
      },
      "source": [
        "### 2. Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zkqq4A8q1V_",
        "colab_type": "code",
        "outputId": "8378a23b-1a9f-4806-92be-590e5b90df73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIz6dNnTrcg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/Datasets for Data Science Projects/twcs.csv'\n",
        "twitter_df = pd.read_csv(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3_XcMHqGhOK",
        "colab_type": "text"
      },
      "source": [
        "### 3. Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l87BwOCGlf6",
        "colab_type": "text"
      },
      "source": [
        "Because this is a new data set, it'll be helpful to use EDA to get a feel for the data, add features, clean it up and explore the data with visuals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jubHmdyLigU",
        "colab_type": "text"
      },
      "source": [
        "*3.1 Looking at the Dataframe*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOmsiPkKFFSx",
        "colab_type": "code",
        "outputId": "11ddf2fa-f8c3-492f-a24b-6fd2c3bddf38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "twitter_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811769</th>\n",
              "      <td>2987947</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:43:51 +0000 2017</td>\n",
              "      <td>@823869 Hey, we'd be happy to look into this f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987948.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811770</th>\n",
              "      <td>2987948</td>\n",
              "      <td>823869</td>\n",
              "      <td>True</td>\n",
              "      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n",
              "      <td>@115714 wtf!? I’ve been having really shitty s...</td>\n",
              "      <td>2987947</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811771</th>\n",
              "      <td>2812240</td>\n",
              "      <td>121673</td>\n",
              "      <td>True</td>\n",
              "      <td>Thu Nov 23 04:13:07 +0000 2017</td>\n",
              "      <td>@143549 @sprintcare You have to go to https://...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2812239.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811772</th>\n",
              "      <td>2987949</td>\n",
              "      <td>AldiUK</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:31:24 +0000 2017</td>\n",
              "      <td>@823870 Sounds delicious, Sarah! 😋 https://t.c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811773</th>\n",
              "      <td>2987950</td>\n",
              "      <td>823870</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n",
              "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
              "      <td>2987951,2987949</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2811774 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         tweet_id   author_id  ...  response_tweet_id in_response_to_tweet_id\n",
              "0               1  sprintcare  ...                  2                     3.0\n",
              "1               2      115712  ...                NaN                     1.0\n",
              "2               3      115712  ...                  1                     4.0\n",
              "3               4  sprintcare  ...                  3                     5.0\n",
              "4               5      115712  ...                  4                     6.0\n",
              "...           ...         ...  ...                ...                     ...\n",
              "2811769   2987947  sprintcare  ...                NaN               2987948.0\n",
              "2811770   2987948      823869  ...            2987947                     NaN\n",
              "2811771   2812240      121673  ...                NaN               2812239.0\n",
              "2811772   2987949      AldiUK  ...                NaN               2987950.0\n",
              "2811773   2987950      823870  ...    2987951,2987949                     NaN\n",
              "\n",
              "[2811774 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abd7D69iLK8u",
        "colab_type": "code",
        "outputId": "571e8a6a-91cb-4868-f098-f6fc5dc938c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "twitter_df['author_id'].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "702777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSWr8t7hho91",
        "colab_type": "code",
        "outputId": "8104fc07-77da-4b1b-dc10-89cd5341e153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(twitter_df['created_at'].min())\n",
        "print(twitter_df['created_at'].max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 01 17:37:48 +0000 2016\n",
            "Wed Sep 28 18:06:15 +0000 2016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u4Ub17tHFgS",
        "colab_type": "text"
      },
      "source": [
        "Intial observations from looking at the dataframe: \n",
        "\n",
        "- The dataset's 2,811,774 rows by seven columns, which is large. \n",
        "    - That could be a chokepoint when running algorithms. Later on I may need to make the dataset smaller by taking a random sample of it, looking at select industries, or only looking at a segment of the data.\n",
        "- There are 702,777 unique authors in this dataset and there are an average of four tweets/author.\n",
        "- The tweets are from the beginning of April through late September in 2016. From a business standpoint, this time period covers quarter two and quarter three financial reporting.\n",
        "\n",
        "Notes on data cleaning:\n",
        "- In the *response_tweet_id* and the *in_response_to_tweet_id* columns, there are NaN values that show there wasn't a reply to a tweet. \n",
        "    - During the data cleaning stage, it could make sense to replace those with zeros.\n",
        "- There's punctuation (like the \"@\" sign and emojis) that'll need to be removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8JuC1edVE5V",
        "colab_type": "text"
      },
      "source": [
        "*3.2 Feature Engineering*\n",
        "\n",
        "I'd like to add features related to the companies, like which industries they belong to, and I'll work on that in that in this section.\n",
        "\n",
        "To get started, I need to isolate the values in the *author_id* column so that it only includes the names of companies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAO1bU0yVZr-",
        "colab_type": "code",
        "outputId": "1183cac9-ffd4-44e6-d631-6528cb76b5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# I'll make a new dataframe to keep track of the changes that I'm making.\n",
        "authors_df = twitter_df.copy()\n",
        "\n",
        "# I'll also make a new variable, called author_alphas, and add it to the authors_dataframe. \n",
        "# This variable will show which variables are alphabetic. And since individuals are represented by numbers, this will tell us which author_ids are companies and which aren't.\n",
        "authors_df['author_alphas'] = authors_df['author_id'].str.isalpha()\n",
        "\n",
        "print(authors_df['author_alphas'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0           True\n",
            "1          False\n",
            "2          False\n",
            "3           True\n",
            "4          False\n",
            "           ...  \n",
            "2811769     True\n",
            "2811770    False\n",
            "2811771    False\n",
            "2811772     True\n",
            "2811773    False\n",
            "Name: author_alphas, Length: 2811774, dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk3Hioprd0Ub",
        "colab_type": "code",
        "outputId": "9c67a38c-cf48-4d06-f9ee-2caaadba8a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# I'll make another variable, called 'author_is_individual', to help me drop the individuals from the dataframe.\n",
        "author_is_individual = authors_df[authors_df['author_alphas'] == False].index\n",
        "\n",
        "authors_df.drop(author_is_individual, inplace=True)\n",
        "\n",
        "authors_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "      <th>author_alphas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
              "      <td>@115712 Can you please send us a private messa...</td>\n",
              "      <td>5,7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:35 +0000 2017</td>\n",
              "      <td>@115713 This is saddening to hear. Please shoo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 20:03:31 +0000 2017</td>\n",
              "      <td>@115713 We understand your concerns and we'd l...</td>\n",
              "      <td>12</td>\n",
              "      <td>16.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id   author_id  ...  in_response_to_tweet_id author_alphas\n",
              "0         1  sprintcare  ...                      3.0          True\n",
              "3         4  sprintcare  ...                      5.0          True\n",
              "5         6  sprintcare  ...                      8.0          True\n",
              "7        11  sprintcare  ...                     12.0          True\n",
              "9        15  sprintcare  ...                     16.0          True\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D6nZRqkLb7i",
        "colab_type": "code",
        "outputId": "9f21f930-babf-44ee-d781-e59691025238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# From looking at the dataframe, my sense is that the table only has companies listed, but I'll double-check that by looking at the values in that column. \n",
        "authors_df['author_alphas'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9H37LwflLi",
        "colab_type": "text"
      },
      "source": [
        "Now that the *author_id* column only has companies listed, I'm closer to being able to do feature engineering with the company information. But there's still more to do, like getting a list of all the company names and seeing how many companies there are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkPazCKhfkfL",
        "colab_type": "code",
        "outputId": "05bc09bb-2eb2-4123-9239-a3c2667556cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# This will give me the list of company names.\n",
        "authors_df['author_id'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sprintcare', 'VerizonSupport', 'ChipotleTweets', 'AskPlayStation',\n",
              "       'marksandspencer', 'MicrosoftHelps', 'ATVIAssist', 'AdobeCare',\n",
              "       'AmazonHelp', 'XboxSupport', 'AirbnbHelp', 'nationalrailenq',\n",
              "       'AirAsiaSupport', 'Morrisons', 'NikeSupport', 'AskAmex',\n",
              "       'McDonalds', 'YahooCare', 'AskLyft', 'UPSHelp', 'Delta',\n",
              "       'AppleSupport', 'Tesco', 'SpotifyCares', 'comcastcares',\n",
              "       'AmericanAir', 'TMobileHelp', 'VirginTrains', 'SouthwestAir',\n",
              "       'AskeBay', 'GWRHelp', 'sainsburys', 'AskPayPal', 'HPSupport',\n",
              "       'ChaseSupport', 'CoxHelp', 'DropboxSupport', 'VirginAtlantic',\n",
              "       'AzureSupport', 'AlaskaAir', 'ArgosHelpers', 'AskTarget',\n",
              "       'GoDaddyHelp', 'CenturyLinkHelp', 'AskPapaJohns', 'askpanera',\n",
              "       'Walmart', 'USCellularCares', 'AsurionCares', 'GloCare',\n",
              "       'NeweggService', 'VirginAmerica', 'DunkinDonuts', 'TfL',\n",
              "       'asksalesforce', 'Kimpton', 'AskCiti', 'IHGService',\n",
              "       'LondonMidland', 'JetBlue', 'BoostCare', 'JackBox', 'AldiUK',\n",
              "       'HiltonHelp', 'GooglePlayMusic', 'OfficeSupport', 'DellCares',\n",
              "       'TwitterSupport', 'GreggsOfficial', 'ATT', 'TacoBellTeam',\n",
              "       'AskRBC', 'ArbysCares', 'NortonSupport', 'AskSeagate',\n",
              "       'sizehelpteam', 'SCsupport', 'MOO', 'AskDSC', 'AskVirginMoney',\n",
              "       'AskRobinhood', 'AWSSupport', 'VMUcare', 'mediatemplehelp',\n",
              "       'AskTigogh', 'PandoraSupport', 'askvisa', 'OPPOCareIN',\n",
              "       'PearsonSupport', 'CarlsJr', 'HotelTonightCX'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1xjZeWzkFSa",
        "colab_type": "code",
        "outputId": "68852ce6-78cc-48dc-f04b-bb122fb75b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "authors_df['author_id'].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYeXZpZmLuPZ",
        "colab_type": "text"
      },
      "source": [
        "I'll use feature engineering to add these variables to the dataframe by building off the list of company names: \n",
        "\n",
        "1. Industry.\n",
        "  - This will list which sector each company's in. This includes banks, retail, restaurants and so on.\n",
        "  - To get the sector information, I went to the US Chamber of Commerce and saw that on their [frequently asked questions page](https://www.uschamber.com/about/about-the-us-chamber/frequently-asked-questions#3) they recommend using [Salesgenie](https://www.salesgenie.com/) to research how companies are classified. From there, I made a Salesgenie profile and used their free, three-day trial to gather data.\n",
        "  - Note: Salesgenie only has information on US companies, but some of the companies in the dataset were from other countries. In those cases, I assigned sectors to companies based off how their American counter-parts had been classified. For instance, I listed the Royal Bank of Canada as a bank because Citibank is also listed as a bank.\n",
        "  - For a full list of non-US companies and the industries they were assigned to, please reference the Appendix.\n",
        "\n",
        "2. NASDAQ Listing.\n",
        "  - Please note that: \n",
        "  1. The NASDAQ information was gathered from [Yahoo! Finance](https://finance.yahoo.com/). For your reference, here's an example of a search where I took the [Adjusted Close Number for Adobe's stock from May 31, 2016](https://finance.yahoo.com/quote/ADBE/history?period1=1462078800&period2=1464757200&interval=1mo&filter=history&frequency=1mo).\n",
        "  2. Some companies that are listed on NASDAQ now, like Uber, weren't listed on the exchange in 2016 because they hadn't gone public yet. \n",
        "  3. In some cases a company's not listed on NASDAQ because it's privately held and may never go public.\n",
        "\n",
        "3. NASDAQ Price (in USD).\n",
        "  - If a company was listed on NASDAQ on May 31, 2016 this will show the adjusted value of how much the stock cost on that day.\n",
        "\n",
        "4. Major Event.\n",
        "  - If a company experienced an event that impacted thousands of people, such as a service outtage, and the event was covered by multiple news sources I recorded that and assigned it a value of one; however, if a company didn't have a major event, it was given a zero.\n",
        "  - For your reference, [here's an example of a search]((https://www.google.com/search?biw=1920&bih=969&tbs=cdr%3A1%2Ccd_min%3A4%2F1%2F2016%2Ccd_max%3A9%2F28%2F2016&tbm=nws&ei=MznTXcm0Eoi8tgWlqqZY&q=london+midland&oq=london+midland&gs_l=psy-ab.3..0l2.39991.41189.0.41514.14.11.0.3.3.0.165.1405.3j8.11.0....0...1c.1.64.psy-ab..1.13.1263...0i131k1.0.X-aRa17UL9k) where I found information about a train derailment that impacted London Midland's services. In the 'major_event' column, I said that a, \"train derailment caused disruption in service\".\n",
        "\n",
        "5. Event Month.\n",
        "  - Because the dataframe covers April 1st through September 28th, I looked for events that occurred during that timeframe and noted the month as a number. For instance, April was four and May was five. In cases where there wasn't a major event, I put down a zero.\n",
        "\n",
        "6. Event Highlights.\n",
        "  - To provide insights, I wrote down a highlight about event.\n",
        "\n",
        "7. Company.\n",
        "  - To make it easier to tell companies and individuals apart, I'll add a column to show if the author of a tweet is a company or an individual. If the author's a company, they'll get assigned a value of one. If it's an individual, the value will be zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbvN147_fiQ7",
        "colab_type": "text"
      },
      "source": [
        "Adding the new features to the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJZodtC9cRqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/Datasets for Data Science Projects/twcs.csv'\n",
        "twitter_df = pd.read_csv(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6amh_jFT0V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def clean_numbers(df, string, int):\n",
        "    #df.loc[(df[string] != int), string] = 0\n",
        "    #return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahyxSYmWTz_W",
        "colab_type": "code",
        "outputId": "414c367d-574e-44ee-c663-699eb3cf780c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# clean_numbers(twitter_df, 'author_id', 1)\n",
        "twitter_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id   author_id  ...  response_tweet_id in_response_to_tweet_id\n",
              "0         1  sprintcare  ...                  2                     3.0\n",
              "1         2      115712  ...                NaN                     1.0\n",
              "2         3      115712  ...                  1                     4.0\n",
              "3         4  sprintcare  ...                  3                     5.0\n",
              "4         5      115712  ...                  4                     6.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_muDjsbePth",
        "colab_type": "code",
        "outputId": "dace627f-cfe9-4301-d50e-b2e6f8e259c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "twitter_df['author_id'].str.contains('\\d', regex=True).replace('True', 'NaN')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          False\n",
              "1           True\n",
              "2           True\n",
              "3          False\n",
              "4           True\n",
              "           ...  \n",
              "2811769    False\n",
              "2811770     True\n",
              "2811771     True\n",
              "2811772    False\n",
              "2811773     True\n",
              "Name: author_id, Length: 2811774, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfIOX3AKjORJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# created some DF with a column named 'numerics'\n",
        "df = pd.DataFrame([2,4,'aaaaa','bbbbbb',10.1,np.nan,'hi'], columns = ['numerics'])\n",
        "list1 = []\n",
        "for i in df.numerics:\n",
        " if type(i) in [int, float]:\n",
        "   list1.append(None)\n",
        " else:\n",
        "   list1.append(i)\n",
        "df['new_column'] = list1\n",
        "print df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua3jsJctsHrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame([2,'4','aaaaa','bbbbbb',10.1,np.nan,'hi'], columns = ['numerics'])\n",
        "list1 = []\n",
        "for i in df.numerics:\n",
        " try:\n",
        "   i = float(i)\n",
        " except:\n",
        "   pass\n",
        " if type(i) in [int, float]:\n",
        "   list1.append(None)\n",
        " else:\n",
        "   list1.append(i)\n",
        "#print list1\n",
        "df['new_column'] = list1\n",
        "print df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC8ycPA63OFP",
        "colab_type": "text"
      },
      "source": [
        "# Dennis, please start here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mqjsBCQjOEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regex_df = twitter_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ufw-gY-1dnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1ec8462f-676b-4a15-9738-55c7c84bd53d"
      },
      "source": [
        "list1 = []\n",
        "\n",
        "for i in regex_df['author_id']:\n",
        " try:\n",
        "   i = float(i)\n",
        " except:\n",
        "   list1.append(None)\n",
        "   pass\n",
        " if type(i) in [int, float]:\n",
        "   list1.append(None)\n",
        " else:\n",
        "   list1.append(i)\n",
        "#print list1\n",
        "regex_df['new_column'] = list1\n",
        "print(regex_df)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-1256df22f4ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m    \u001b[0mlist1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#print list1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mregex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_column'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3486\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3487\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3564\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3565\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3748\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3749\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3751\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of values does not match length of index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBjXbx64ml0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7eHu3_EmlgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHGVEMgZmlGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txaf5PrcT_Gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7aPreWuTztt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzLW3ZBkT5CF",
        "colab_type": "code",
        "outputId": "c6066049-454b-4df5-ef77-b49335511f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "twitter_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id   author_id  ...  response_tweet_id in_response_to_tweet_id\n",
              "0         1  sprintcare  ...                  2                     3.0\n",
              "1         2      115712  ...                NaN                     1.0\n",
              "2         3      115712  ...                  1                     4.0\n",
              "3         4  sprintcare  ...                  3                     5.0\n",
              "4         5      115712  ...                  4                     6.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn0Qg7_UZuLu",
        "colab_type": "code",
        "outputId": "c6ee5251-4497-4a45-82e4-b3777094dad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "twitter_df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2811769</th>\n",
              "      <td>2987947</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:43:51 +0000 2017</td>\n",
              "      <td>@823869 Hey, we'd be happy to look into this f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987948.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811770</th>\n",
              "      <td>2987948</td>\n",
              "      <td>823869</td>\n",
              "      <td>True</td>\n",
              "      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n",
              "      <td>@115714 wtf!? I’ve been having really shitty s...</td>\n",
              "      <td>2987947</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811771</th>\n",
              "      <td>2812240</td>\n",
              "      <td>121673</td>\n",
              "      <td>True</td>\n",
              "      <td>Thu Nov 23 04:13:07 +0000 2017</td>\n",
              "      <td>@143549 @sprintcare You have to go to https://...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2812239.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811772</th>\n",
              "      <td>2987949</td>\n",
              "      <td>AldiUK</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:31:24 +0000 2017</td>\n",
              "      <td>@823870 Sounds delicious, Sarah! 😋 https://t.c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811773</th>\n",
              "      <td>2987950</td>\n",
              "      <td>823870</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n",
              "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
              "      <td>2987951,2987949</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         tweet_id   author_id  ...  response_tweet_id in_response_to_tweet_id\n",
              "2811769   2987947  sprintcare  ...                NaN               2987948.0\n",
              "2811770   2987948      823869  ...            2987947                     NaN\n",
              "2811771   2812240      121673  ...                NaN               2812239.0\n",
              "2811772   2987949      AldiUK  ...                NaN               2987950.0\n",
              "2811773   2987950      823870  ...    2987951,2987949                     NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iyey_9ixepW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_df['author_id'] = twitter_df['author_id'].replace()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAm2ZXnAepQ8",
        "colab_type": "code",
        "outputId": "435ca866-c279-4c80-ae7b-5247aad1a246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "twitter_df['author_id'].str.isnumeric()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          False\n",
              "1           True\n",
              "2           True\n",
              "3          False\n",
              "4           True\n",
              "           ...  \n",
              "2811769    False\n",
              "2811770     True\n",
              "2811771     True\n",
              "2811772    False\n",
              "2811773     True\n",
              "Name: author_id, Length: 2811774, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ0kWgHiepLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def function(string):\n",
        "  twitter_df.loc[(twitter_df[string]) == twitter_df['author_id'].str.isnumeric(), string] = 1\n",
        "  return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZQYML9HfPn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "function('author_id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piIC1vUCf7Ei",
        "colab_type": "code",
        "outputId": "b44a222b-9ae1-4f8e-cfdc-9455bd29a821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "twitter_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id   author_id  ...  response_tweet_id in_response_to_tweet_id\n",
              "0         1  sprintcare  ...                  2                     3.0\n",
              "1         2      115712  ...                NaN                     1.0\n",
              "2         3      115712  ...                  1                     4.0\n",
              "3         4  sprintcare  ...                  3                     5.0\n",
              "4         5      115712  ...                  4                     6.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsvHf4EzfPiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_author_id(string, range):\n",
        "  twitter_df.loc[(twitter_df[string] == range), string] = 'NaN'\n",
        "  return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klq9Yag3fPZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_ipFXu2fPSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnbyZkqmcLb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['BrandName'].replace(['ABC', 'AB'], 'A')\n",
        "\n",
        "df['BrandName'].replace(\n",
        "    to_replace=['ABC', 'AB'],\n",
        "    value='A',\n",
        "    inplace=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBBVnBK8cLTC",
        "colab_type": "code",
        "outputId": "a94e7bea-9abf-4ff3-ab2e-b5942cecfed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "twitter_df['author_id'] = twitter_df['author_id'].replace(to_replace=[115712], value='NaN', inplace=True)\n",
        "twitter_df['author_id']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          None\n",
              "1          None\n",
              "2          None\n",
              "3          None\n",
              "4          None\n",
              "           ... \n",
              "2811769    None\n",
              "2811770    None\n",
              "2811771    None\n",
              "2811772    None\n",
              "2811773    None\n",
              "Name: author_id, Length: 2811774, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naI0QCz6T4y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_author_id(string, range):\n",
        "  twitter_df.loc[(twitter_df[string] == range), string] = 'NaN'\n",
        "  return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk3BBYTpVEXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_author_id('author_id', 115712-823870)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SikIJG00VET6",
        "colab_type": "code",
        "outputId": "2340ae11-78c9-41c0-eb58-0d33aba00a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "twitter_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id author_id  ...  response_tweet_id in_response_to_tweet_id\n",
              "0         1      None  ...                  2                     3.0\n",
              "1         2      None  ...                NaN                     1.0\n",
              "2         3      None  ...                  1                     4.0\n",
              "3         4      None  ...                  3                     5.0\n",
              "4         5      None  ...                  4                     6.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0HLmNibVEOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMAbKzLLT4vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCAzUEi6T4qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jrksFMLb3_y",
        "colab_type": "code",
        "outputId": "c6e8de7f-46c5-4175-b8b1-8ea4a83c8c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0obIQw97b38o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/Industry List Spreadsheet.xlsx'\n",
        "industry_list_df = pd.read_excel(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTweGW1fb33f",
        "colab_type": "code",
        "outputId": "e772ef3a-028d-4d50-bd4b-ba0809d3c29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "industry_list_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>industry</th>\n",
              "      <th>nasdaq_listing</th>\n",
              "      <th>nasdaq_price</th>\n",
              "      <th>major_event</th>\n",
              "      <th>event_month</th>\n",
              "      <th>event_highlights</th>\n",
              "      <th>author_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Computer - Software Developers</td>\n",
              "      <td>1</td>\n",
              "      <td>95.79</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Launched new service.</td>\n",
              "      <td>AdobeCare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Airline Companies</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AirAsiaSupport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Marketing Consultants</td>\n",
              "      <td>1</td>\n",
              "      <td>22.68</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>Adopted anti-discrimination policies.</td>\n",
              "      <td>AirbnbHelp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Airline Companies</td>\n",
              "      <td>1</td>\n",
              "      <td>54.74</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Bought Virgin America.</td>\n",
              "      <td>AlaskaAir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Grocers - Retail</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AldiUK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>Commuter &amp; Passenger Rail Service</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VirginTrains</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>Cellular Telephones (Services)</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Pokemon Go ported to Dreamcast.</td>\n",
              "      <td>VMUcare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Department Stores</td>\n",
              "      <td>1</td>\n",
              "      <td>67.51</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Walmart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Computer Software - Manufacturers</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>New product: Xbox One S announced.</td>\n",
              "      <td>XboxSupport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>Internet Service</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Bought by Verizon in $4.8 billion deal.</td>\n",
              "      <td>YahooCare</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             industry  ...       author_id\n",
              "0      Computer - Software Developers  ...       AdobeCare\n",
              "1                   Airline Companies  ...  AirAsiaSupport\n",
              "2               Marketing Consultants  ...      AirbnbHelp\n",
              "3                   Airline Companies  ...       AlaskaAir\n",
              "4                    Grocers - Retail  ...          AldiUK\n",
              "..                                ...  ...             ...\n",
              "86  Commuter & Passenger Rail Service  ...    VirginTrains\n",
              "87     Cellular Telephones (Services)  ...         VMUcare\n",
              "88                  Department Stores  ...         Walmart\n",
              "89  Computer Software - Manufacturers  ...     XboxSupport\n",
              "90                   Internet Service  ...       YahooCare\n",
              "\n",
              "[91 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1OlSLWwb30X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reordering the twitter_df.\n",
        "cols = twitter_df.columns.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPQWVKpjeHco",
        "colab_type": "code",
        "outputId": "9250fb56-e78a-4338-88fa-56d5c8b87b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "cols = cols[-6:] + cols[:-6]\n",
        "cols"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['author_id',\n",
              " 'inbound',\n",
              " 'created_at',\n",
              " 'text',\n",
              " 'response_tweet_id',\n",
              " 'in_response_to_tweet_id',\n",
              " 'tweet_id']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP0d_aixeHXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols_df = twitter_df[cols] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etxmmy8Nb3xP",
        "colab_type": "code",
        "outputId": "692e8f9f-8074-4f8a-d112-fb810ccd6c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        }
      },
      "source": [
        "cols_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "      <th>tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811769</th>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:43:51 +0000 2017</td>\n",
              "      <td>@823869 Hey, we'd be happy to look into this f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987948.0</td>\n",
              "      <td>2987947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811770</th>\n",
              "      <td>823869</td>\n",
              "      <td>True</td>\n",
              "      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n",
              "      <td>@115714 wtf!? I’ve been having really shitty s...</td>\n",
              "      <td>2987947</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811771</th>\n",
              "      <td>121673</td>\n",
              "      <td>True</td>\n",
              "      <td>Thu Nov 23 04:13:07 +0000 2017</td>\n",
              "      <td>@143549 @sprintcare You have to go to https://...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2812239.0</td>\n",
              "      <td>2812240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811772</th>\n",
              "      <td>AldiUK</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:31:24 +0000 2017</td>\n",
              "      <td>@823870 Sounds delicious, Sarah! 😋 https://t.c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987950.0</td>\n",
              "      <td>2987949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811773</th>\n",
              "      <td>823870</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n",
              "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
              "      <td>2987951,2987949</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2811774 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          author_id  inbound  ... in_response_to_tweet_id tweet_id\n",
              "0        sprintcare    False  ...                     3.0        1\n",
              "1            115712     True  ...                     1.0        2\n",
              "2            115712     True  ...                     4.0        3\n",
              "3        sprintcare    False  ...                     5.0        4\n",
              "4            115712     True  ...                     6.0        5\n",
              "...             ...      ...  ...                     ...      ...\n",
              "2811769  sprintcare    False  ...               2987948.0  2987947\n",
              "2811770      823869     True  ...                     NaN  2987948\n",
              "2811771      121673     True  ...               2812239.0  2812240\n",
              "2811772      AldiUK    False  ...               2987950.0  2987949\n",
              "2811773      823870     True  ...                     NaN  2987950\n",
              "\n",
              "[2811774 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbzT1iQ1RQGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1=df1.merge(df2, on='product_id', how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMc1rw8kR4tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_df = industry_list_df.merge(cols_df, on='author_id', how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti6fhPnpR4po",
        "colab_type": "code",
        "outputId": "ad88472d-918b-4462-8ee7-7e315641b1c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "combined_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>industry</th>\n",
              "      <th>nasdaq_listing</th>\n",
              "      <th>nasdaq_price</th>\n",
              "      <th>major_event</th>\n",
              "      <th>event_month</th>\n",
              "      <th>event_highlights</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "      <th>tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Computer - Software Developers</td>\n",
              "      <td>1</td>\n",
              "      <td>95.79</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Launched new service.</td>\n",
              "      <td>AdobeCare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:14:17 +0000 2017</td>\n",
              "      <td>@115767 Sorry that this isn't more simple... l...</td>\n",
              "      <td>241</td>\n",
              "      <td>242.0</td>\n",
              "      <td>240.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Computer - Software Developers</td>\n",
              "      <td>1</td>\n",
              "      <td>95.79</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Launched new service.</td>\n",
              "      <td>AdobeCare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 01 00:53:51 +0000 2017</td>\n",
              "      <td>@115767 Would you please DM the Adobe Product ...</td>\n",
              "      <td>244</td>\n",
              "      <td>241.0</td>\n",
              "      <td>243.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Computer - Software Developers</td>\n",
              "      <td>1</td>\n",
              "      <td>95.79</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Launched new service.</td>\n",
              "      <td>AdobeCare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:09:19 +0000 2017</td>\n",
              "      <td>@115767 Hi Jason, could you please try resetti...</td>\n",
              "      <td>242,246</td>\n",
              "      <td>247.0</td>\n",
              "      <td>245.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Computer - Software Developers</td>\n",
              "      <td>1</td>\n",
              "      <td>95.79</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Launched new service.</td>\n",
              "      <td>AdobeCare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 20:52:11 +0000 2017</td>\n",
              "      <td>@115767 Hi Jason, please let us know if there ...</td>\n",
              "      <td>247</td>\n",
              "      <td>250.0</td>\n",
              "      <td>249.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Computer - Software Developers</td>\n",
              "      <td>1</td>\n",
              "      <td>95.79</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Launched new service.</td>\n",
              "      <td>AdobeCare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:12:21 +0000 2017</td>\n",
              "      <td>@115768 Hi Jeffrey, were you able to update to...</td>\n",
              "      <td>252</td>\n",
              "      <td>253.0</td>\n",
              "      <td>251.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039868</th>\n",
              "      <td>Internet Service</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Bought by Verizon in $4.8 billion deal.</td>\n",
              "      <td>YahooCare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 29 19:40:06 +0000 2017</td>\n",
              "      <td>@345629 Sorry to hear you're having those trou...</td>\n",
              "      <td>2962601,2962602</td>\n",
              "      <td>2962603.0</td>\n",
              "      <td>2962600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039869</th>\n",
              "      <td>Internet Service</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Bought by Verizon in $4.8 billion deal.</td>\n",
              "      <td>YahooCare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 29 18:45:06 +0000 2017</td>\n",
              "      <td>@345629 Sorry to hear you're having trouble re...</td>\n",
              "      <td>2962608</td>\n",
              "      <td>2962609.0</td>\n",
              "      <td>2962607.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039870</th>\n",
              "      <td>Internet Service</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Bought by Verizon in $4.8 billion deal.</td>\n",
              "      <td>YahooCare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 29 17:56:33 +0000 2017</td>\n",
              "      <td>@701200 Glad to hear it's up an running. Pleas...</td>\n",
              "      <td>2962611</td>\n",
              "      <td>2962612.0</td>\n",
              "      <td>2962610.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039871</th>\n",
              "      <td>Internet Service</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Bought by Verizon in $4.8 billion deal.</td>\n",
              "      <td>YahooCare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 29 17:45:06 +0000 2017</td>\n",
              "      <td>@701200 I see no immediate issues with Yahoo M...</td>\n",
              "      <td>2962612</td>\n",
              "      <td>2962614.0</td>\n",
              "      <td>2962613.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039872</th>\n",
              "      <td>Internet Service</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Bought by Verizon in $4.8 billion deal.</td>\n",
              "      <td>YahooCare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 29 23:27:51 +0000 2017</td>\n",
              "      <td>@820398 Please send us a direct message with t...</td>\n",
              "      <td>2974703,2974704</td>\n",
              "      <td>2974705.0</td>\n",
              "      <td>2974702.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1039873 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                               industry  ...   tweet_id\n",
              "0        Computer - Software Developers  ...      240.0\n",
              "1        Computer - Software Developers  ...      243.0\n",
              "2        Computer - Software Developers  ...      245.0\n",
              "3        Computer - Software Developers  ...      249.0\n",
              "4        Computer - Software Developers  ...      251.0\n",
              "...                                 ...  ...        ...\n",
              "1039868                Internet Service  ...  2962600.0\n",
              "1039869                Internet Service  ...  2962607.0\n",
              "1039870                Internet Service  ...  2962610.0\n",
              "1039871                Internet Service  ...  2962613.0\n",
              "1039872                Internet Service  ...  2974702.0\n",
              "\n",
              "[1039873 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz9BJqi0R4kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzR3OzASRQDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwUQ4q6ZRP-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT5rB6RURP6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BtESosrb3r-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxZQgnzYvXSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To get started with adding the features, I'll make a new dataframe.\n",
        "feature_engineered_df = twitter_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCyvcE7NYoE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Because I need to add several features, I'm going to define a function to make this go faster.\n",
        "def add_feature(str):\n",
        "  feature_engineered_df[str] = twitter_df['author_id']\n",
        "  return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBfoDdbPYoHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For consistency, I'll follow the writing style that's in the original dataframe.\n",
        "\n",
        "add_feature('industry')\n",
        "add_feature('nasdaq_listing')\n",
        "add_feature('nasdaq_price')\n",
        "add_feature('major_event')\n",
        "add_feature('event_month')\n",
        "add_feature('event_highlights')\n",
        "add_feature('company')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5EfssIvYoJH",
        "colab_type": "code",
        "outputId": "2d2b1a4f-0430-4ca7-bf7f-c9a5aba27081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Double-checking to make sure the features were added correctly.\n",
        "feature_engineered_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "      <th>industry</th>\n",
              "      <th>nasdaq_listing</th>\n",
              "      <th>nasdaq_price</th>\n",
              "      <th>major_event</th>\n",
              "      <th>event_month</th>\n",
              "      <th>event_highlights</th>\n",
              "      <th>company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>sprintcare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id   author_id  inbound  ... event_month event_highlights     company\n",
              "0         1  sprintcare    False  ...  sprintcare       sprintcare  sprintcare\n",
              "1         2      115712     True  ...      115712           115712      115712\n",
              "2         3      115712     True  ...      115712           115712      115712\n",
              "3         4  sprintcare    False  ...  sprintcare       sprintcare  sprintcare\n",
              "4         5      115712     True  ...      115712           115712      115712\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZAnLiVphdkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The new features are copies of 'author_id', so I'll define a feature to replace existing values with new ones.\n",
        "# Please note that while a couple of the new features use strings, the others use integers, so I'll define separate functions for each data type.\n",
        "def replace_string_values(str0, str1, str2, str3, str4, str5, str6, str7, str8, str9, str10, str11, str12, str13, str14, str15, str16, str17, str18, str19, str20, str21, str22, str23, str24, str25, str26,\n",
        "                   str27, str28, str29, str30, str31, str32, str33, str34, str35, str36, str37, str38, str39, str40, str41, str42, str43, str44, str45, str46, str47, str48, str49, str50, str51, str52,\n",
        "                   str53, str54, str55, str56, str57, str58, str59, str60, str61, str62, str63, str64, str65, str66, str67, str68, str69, str70, str71, str72, str73, str74, str75, str76, str77, str78, \n",
        "                   str79, str80, str81, str82, str83, str84, str85, str86, str87, str88, str89, str90, str91):\n",
        "  \n",
        "  # Strings 1-10.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AdobeCare', str1)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AirAsiaSupport', str2)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AirbnbHelp', str3)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AlaskaAir', str4)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AldiUK', str5)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AmazonHelp', str6)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AmericanAir', str7)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AppleSupport', str8)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ArbysCares', str9)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ArgosHelpers', str10)\n",
        "\n",
        "  # Strings 11-20.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskAmex', str11)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskCiti', str12)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskDSC', str13)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AkeBaye', str14)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskLyft', str15)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('askpanera', str16)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskPapaJohns', str17)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskPayPal', str18)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskPlayStation', str19)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskRBC', str20)\n",
        "\n",
        "  # Strings 21-30.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskRobinhood', str21)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('asksalesforce', str22)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskSeagate', str23)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskTarget', str24)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskTigogh', str25)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskVirginMoney', str26)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('askvisa', str27)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AsurionCares', str28)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ATT', str29)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ATVIAssist', str30)\n",
        "\n",
        "  # Strings 31-40.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AWSSupport', str31)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AzureSupport', str32)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('BoostCare', str33)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('CarlsJr', str34)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('CenturyLinkHelp', str35)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ChaseSupport', str36)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ChipotleTweets', str37)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('comcastcares', str38)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('CoxHelp', str39)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('DellCares', str40)\n",
        "\n",
        "  # Strings 41-50.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Delta', str41)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('DropboxSupport', str42)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('DunkinDonuts', str43)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('GloCare', str44)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('GoDaddyHelp', str45)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('GooglePlayMusic', str46)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('GreggsOfficial', str47)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('GWRHelp', str48)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('HiltonHelp', str49)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('HotelTonightCX', str50)\n",
        "\n",
        "  # Strings 51-60.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('HPSupport', str51)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('IHGService', str52)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('JackBox', str53)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('JetBlue', str54)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Kimpton', str55)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('LondonMidland', str56)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('marksandspencer', str57)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('McDonalds', str58)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('mediatemplehelp', str59)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('MicrosoftHelps', str60)\n",
        "\n",
        "  # Strings 61-70.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('MOO', str61)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Morrisons', str62)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('nationalrailenq', str63)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('NeweggService', str64)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('NikeSupport', str65)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('NortonSupport', str66)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('OfficeSupport', str67)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('OPPOCareIN', str68)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('PandoraSupport', str69)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('PearsonSupport', str70)\n",
        "\n",
        "  # Strings 71-80.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('sainsburys', str71)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Scsupport', str72)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('sizehelpteam', str73)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('SouthwestAir', str74)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('SpotifyCares', str75)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('sprintcare', str76)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('TacoBellTeam', str77)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Tesco', str78)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('TfL', str79)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('TMobileHelp', str80)\n",
        "\n",
        "  # Strings 81-91.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('TwitterSupport', str81)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('UPSHelp', str82)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('USCellularCares', str83)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('VerizonSupport', str84)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('VirginAmerica', str85)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('VirginAtlantic', str86)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('VirginTrains', str87)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('VMUcare', str88)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Walmart', str89)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('XboxSupport', str90)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('YahooCare', str91)\n",
        "\n",
        "  return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsCyzIFohdm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Before I define the second function for replacing numbers, I'll update the 'industry' column.\n",
        "replace_string_values(# String 0.\n",
        "                      'industry',\n",
        "\n",
        "                      # Strings 1-10.\n",
        "                      'Computer - Software Developers', 'Airline Companies', 'Marketing Consultants', 'Airline Companies', 'Grocers - Retail', 'Internet & Catalog Shopping', 'Airline Companies', \n",
        "                      'Computers - Electronic - Manufacturers', 'Restaurants', 'Retail',\n",
        "\n",
        "                      # Strings 11-20.\n",
        "                      'Credit Card & Other Credit Plans', 'Banks', 'Retail', 'E-Commerce', 'Taxicabs & Transportation Service', 'Restaurants', 'Restaurant Management', 'Bill Paying Service', 'Video Games - Manufacturers', \n",
        "                      'Banks', \n",
        "                      \n",
        "                      # Strings 21-30.\n",
        "                      'Nonclassified Establishments', 'Computer Software', 'Computer Software Storage Devices (Manufacturers)', 'Department Stores', 'Cellular Telephones (Services)', 'Banks', \n",
        "                      'Credit Card & Other Credit Plans', 'Insurance', 'Telephone Companies', 'Video Games - Manufacturers', \n",
        "                      \n",
        "                      # Strings 31-40.\n",
        "                      'Internet & Catalog Shopping', 'Computer Software - Manufacturers', 'Cellular Telephones (Services)', 'Restaurants', 'Telecommunications Services', 'Banks', 'Restaurant Management', \n",
        "                      'Television - Cable & Catv', 'Television - Cable & Catv', 'Computers & Computer Equipment Wholesale / Manufacturers',\n",
        "\n",
        "                      # Strings 41-50.\n",
        "                      'Airline Companies', 'Computer Software', 'Restaurant Holding Companies', 'Cellular Telephones (Services)', 'Website Hosting', 'Internet Search Engines', ',Restaurants', \n",
        "                      'Commuter & Passenger Rail Service', 'Hotel & Motel Management', 'Online Services', \n",
        "                      \n",
        "                      # Strings 51-60.\n",
        "                      'Computers - Electronic - Manufacturers', 'Hotel & Motel Management', 'Restaurant Management', 'Airline Companies', 'Hotel & Motel Management', 'Commuter & Passenger Rail Service', \n",
        "                      'Grocers - Retail', 'Restaurants', 'Website Hosting', 'Computer Software - Manufacturers', \n",
        "                      \n",
        "                      # Strings 61-70.\n",
        "                      'Artists - Commercial', 'Grocers - Retail', 'Commuter & Passenger Rail Service', 'E-Commerce', 'Rubber & Plastics Footwear (Manufacturers)', 'Computer Software - Manufacturers', \n",
        "                      'Computer Software - Manufacturers', 'Cellular Telephone (Services)', 'Radio Stations & Broadcasting Companies', 'Education', \n",
        "                      \n",
        "                      # Strings 71-80.\n",
        "                      'Grocers - Retail', 'Radio Stations & Broadcasting Companies', 'Retail', 'Airline Companies', 'Radio Stations & Broadcasting Companies', 'Cellular Telephones (Services)', \n",
        "                      'Restaurant Management', 'Grocers - Retail', 'Commuter & Passenger Rail Service', 'Cellular Telephones (Services)', \n",
        "                      \n",
        "                      # Strings 81-90.\n",
        "                      'Social Media', 'Mailing & Shipping Services', 'Cellular Telephones (Services)', \n",
        "                      'Telecommunications Services', 'Airline Companies', 'Airline Companies', 'Commuter & Passenger Rail Service', 'Cellular Telephones (Services)', 'Department Stores', 'Computer Software - Manufacturers', \n",
        "                      'Internet Service')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM1yyUZUmsmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In next steps, talk about how this could be approached differently.\n",
        "# This was done for the scope of this project. Instead of coding it in here, could maintain it in a spreadsheet or a database.\n",
        "# Ask PM for a recommendation on someone elese who could give feedback."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COE46eHUeR9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next I'll update the 'event_highlights' column.\n",
        "replace_string_values(# String 0.\n",
        "                      'event_highlights', \n",
        "                      \n",
        "                      # Strings 1-10.\n",
        "                      'launched new service', 'NaN', 'adopted anti-discrimination policies', 'bought Virgin America', 'NaN', 'high demand for Amazon Prime Day deals lead to issues at customer check out',\n",
        "                      'thousands of customers missed their flights because of airport security lines', 'apple given illegal tax benefits', 'new sandwhich launch', 'bought by Sainsburys', \n",
        "\n",
        "                      # Strings 11-20.\n",
        "                      'amex cards do not work at Costco anymore', 'closing Venezuela accounts because of financial crisis', 'NaN', 'NaN', 'left Austin, TX because of voting results on using fingerprints for background checks', \n",
        "                      'sued for serving child a meal that caused an allergic reaction', 'NaN', 'closed North Carolina facility due to company values and law change', 'NaN', 'NaN', \n",
        "               \n",
        "                      # Strings 21-30.\n",
        "                      'NaN', 'bought Demandware', 'seagate cutting 6,500 jobs', 'target boycotted over bathroom policies', 'launched customer loyalty program', 'NaN', 'lawsuit', 'NaN', 'ended data overage fees', 'NaN', \n",
        "               \n",
        "                      # Strings 31-40.\n",
        "                      'earned record profits', 'NaN', 'NaN', 'NaN', 'NaN' 'raised minimum wage for employees', 'announced partnership with Virginia Tech to deliver burritos via drone', 'bought Dreamworks animation', \n",
        "                      'service outage', 'dell closed $60 billion merger', \n",
        "\n",
        "                      # Strings 41-50.\n",
        "                      'technical issue with computers lead to grounded flights and service disruption', 'dropbox was hacked and 60+ million credentials were stolen', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', \n",
        "                      'train derailment caused disruption in service', 'NaN', 'launched in-app concierge service', \n",
        "               \n",
        "                      # Strings 51-60.\n",
        "                      'NaN', 'NaN', 'new product release', 'launched historic flight to Cuba', 'NaN', 'train derailment caused disruption in service', 'NaN', 'NaN', 'NaN', 'bought LinkedIn', \n",
        "               \n",
        "                      # Strings 61-70.\n",
        "                      'NaN', 'NaN', 'NaN', 'NaN', 'discontinuing production of golf equipment', 'critical software vulnerabilities found', 'NaN', 'NaN', 'new service launched', 'NaN', \n",
        "               \n",
        "                      # Strings 71-80.\n",
        "                      'bought Argos', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'started offering unlimited data plan', \n",
        "               \n",
        "                      # Strings 81-90.\n",
        "                      'NaN', 'hiring 95,000 seasonal employees', 'NaN', 'bought Yahoo in $4.8 billion deal', 'bought by Alaska Airlines', 'NaN', 'NaN', \n",
        "                      'Pokemon Go ported to Dreamcast', 'NaN', 'new product: Xbox One S announced', 'bought by Verizon in $4.8 billion deal', 'bought LinkedIn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aDs5vmBx0pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's the function for replacing numbers:\n",
        "def replace_number_values(str0, int0, int1, int2, int3, int4, int5, int6, int7, int8, int9, int10, int11, int12, int13, int14, int15, int16, int17, int18, int19, int20, int21, int22, int23, int24, int25,\n",
        "                   int26, int27, int28, int29, int30, int31, int32, int33, int34, int35, int36, int37, int38, int39, int40, int41, int42, int43, int44, int45, int46, int47, int48, int49, int50, int51,\n",
        "                   int52, int53, int54, int55, int56, int57, int58, int59, int60, int61, int62, int63, int64, int65, int66, int67, int68, int69, int70, int71, int72, int73, int74, int75, int76, int77, \n",
        "                   int78, int79, int80, int81, int82, int83, int84, int85, int86, int87, int88, int89, int90):\n",
        "  \n",
        "  # Integers 0-9.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AdobeCare', int0)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AirAsiaSupport', int1)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AirbnbHelp', int2)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AlaskaAir', int3)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AldiUK', int4)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AmazonHelp', int5)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AmericanAir', int6)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AppleSupport', int7)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ArbysCares', int8)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ArgosHelpers', int9)\n",
        "\n",
        "  # Integers 10-19.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskAmex', int10)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskCiti', int11)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskDSC', int12)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AkeBaye', int13)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskLyft', int14)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('askpanera', int15)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskPapaJohns', int16)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskPayPal', int17)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskPlayStation', int18)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskRBC', int19)\n",
        "\n",
        "  # Integers 20-29.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskRobinhood', int20)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('asksalesforce', int21)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskSeagate', int22)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskTarget', int23)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskTigogh', int24)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AskVirginMoney', int25)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('askvisa', int26)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AsurionCares', int27)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ATT', int28)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ATVIAssist', int29)\n",
        "\n",
        "  # Integers 30-39.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AWSSupport', int30)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('AzureSupport', int31)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('BoostCare', int32)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('CarlsJr', int33)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('CenturyLinkHelp', int34)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ChaseSupport', int35)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('ChipotleTweets', int36)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('comcastcares', int37)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('CoxHelp', int38)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('DellCares', int39)\n",
        "\n",
        "  # Integers 40-49.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Delta', int40)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('DropboxSupport', int41)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('DunkinDonuts', int42)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('GloCare', int43)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('GoDaddyHelp', int44)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('GooglePlayMusic', int45)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('GreggsOfficial', int46)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('GWRHelp', int47)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('HiltonHelp', int48)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('HotelTonightCX', int49)\n",
        "\n",
        "  # Integers 50-59.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('HPSupport', int50)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('IHGService', int51)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('JackBox', int52)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('JetBlue', int53)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Kimpton', int54)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('LondonMidland', int55)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('marksandspencer', int56)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('McDonalds', int57)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('mediatemplehelp', int58)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('MicrosoftHelps', int59)\n",
        "\n",
        "  # Integers 60-69.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('MOO', int60)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Morrisons', int61)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('nationalrailenq', int62)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('NeweggService', int63)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('NikeSupport', int64)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('NortonSupport', int65)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('OfficeSupport', int66)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('OPPOCareIN', int67)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('PandoraSupport', int68)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('PearsonSupport', int69)\n",
        "\n",
        "  # Integers 70-79.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('sainsburys', int70)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Scsupport', int71)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('sizehelpteam', int72)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('SouthwestAir', int73)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('SpotifyCares', int74)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('sprintcare', int75)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('TacoBellTeam', int76)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Tesco', int77)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('TfL', int78)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('TMobileHelp', int79)\n",
        "\n",
        "  # Integers 80-90.\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('TwitterSupport', int80)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('UPSHelp', int81)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('USCellularCares', int82)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('VerizonSupport', int83)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('VirginAmerica', int84)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('VirginAtlantic', int85)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('VirginTrains', int86)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('VMUcare', int87)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('Walmart', int88)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('XboxSupport', int89)\n",
        "  feature_engineered_df[str0] = feature_engineered_df[str0].replace('YahooCare', int90)\n",
        "\n",
        "  return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmZz-vQ00Bv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Updating the 'nasdaq_listing' column.\n",
        "replace_number_values(# String 0.\n",
        "                      'nasdaq_listing', \n",
        "                      \n",
        "                      # Integers 0-9.\n",
        "                      1, 0, 1, 1, 0, 1, 1, 1, 0, 0, \n",
        "                      \n",
        "                      # Integers 10-19.\n",
        "                      0, 0, 0, 1, 0, 0, 1, 1, 0, 1, \n",
        "                      \n",
        "                      # Integers 20-29.\n",
        "                      0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
        "\n",
        "                      # Integers 30-39.\n",
        "                      1, 1, 0, 0, 1, 1, 1, 1, 0, 0, \n",
        "\n",
        "                      # Integers 40-49.\n",
        "                      1, 0, 1, 0, 1, 0, 1, 0, 1, 0, \n",
        "                      \n",
        "                      # Integers 50-59.\n",
        "                      1, 1, 0, 1, 0, 0, 1, 1, 0, 1, \n",
        "                      \n",
        "                      # Integers 60-69.\n",
        "                      0, 0, 0, 0, 1, 0, 1, 0, 1, 1, \n",
        "                      \n",
        "                      # Integers 70-79.\n",
        "                      0, 0, 0, 1, 0, 1, 0, 1, 0, 1, \n",
        "                      \n",
        "                      # Integers 80-90.\n",
        "                      1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG9oAbkQr6B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Updating the 'nasdaq_price' column. \n",
        "replace_number_values(# String 0.\n",
        "                      'nasdaq_price', \n",
        "                      \n",
        "                      # Integers 0-9.\n",
        "                      96, 0, 23, 55, 0, 716, 27, 90, 0, 0, \n",
        "                      \n",
        "                      # Integers 10-19.\n",
        "                      0, 0, 0, 23, 0, 0, 65, 37, 0, 51, \n",
        "                      \n",
        "                      # Integers 20-29.\n",
        "                      0, 79, 20, 62, 0, 292, 73, 0, 36, 0, \n",
        "                      \n",
        "                      # Integers 30-39.\n",
        "                      716, 48, 0, 0, 21, 58, 403, 31, 0, 0,  \n",
        "                      \n",
        "                      # Integers 40-49.\n",
        "                      36, 0, 41, 0, 31, 0, 1146, 0, 45, 0,\n",
        "                      \n",
        "                      # Integers 50-59.\n",
        "                      11, 37, 0, 17, 0, 0, 335, 110, 0, 48, \n",
        "                      \n",
        "                      # Integers 60-69.\n",
        "                      0, 0, 0, 0, 53, 0, 48, 0, 4, 11, \n",
        "                      \n",
        "                      # Integers 70-79.\n",
        "                      0, 0, 0, 38, 0, 5, 0, 7, 0, 43, \n",
        "                      \n",
        "                      # Integers 80-90.\n",
        "                      17, 97, 39, 48, 0, 0, 0, 0, 68, 0, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQLq03xauz3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Updating the 'major_event' column.\n",
        "replace_number_values(# String 0.\n",
        "                      'major_event', \n",
        "                      \n",
        "                      # Integers 0-9.\n",
        "                      1, 0, 1, 1, 0, 1, 1, 1, 1, 1, \n",
        "                      \n",
        "                      # Integers 10-19.\n",
        "                      1, 1, 0, 0, 1, 1, 0, 1, 0, 0, \n",
        "                      \n",
        "                      # Integers 20-29.\n",
        "                      0, 1, 1, 1, 1, 0, 1, 0, 1, 0, \n",
        "                      \n",
        "                      # Integers 30-39.\n",
        "                      1, 0, 0, 0, 0, 1, 1, 1, 1, 1, \n",
        "                      \n",
        "                      # Integers 40-49.\n",
        "                      1, 1, 0, 0, 0, 0, 0, 1, 0, 1, \n",
        "                      \n",
        "                      # Integers 50-59.\n",
        "                      0, 0, 1, 1, 0, 1, 0, 0, 0, 1, \n",
        "\n",
        "                      # Integers 60-69.\n",
        "                      0, 0, 0, 0, 1, 1, 0, 0, 1, 0, \n",
        "                      \n",
        "                      # Integers 70-79.\n",
        "                      1, 0, 0, 0, 0, 0, 0, 0, 0, 1, \n",
        "                      \n",
        "                      # Integers 80-90.\n",
        "                      0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G32EFr0JvsNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Updating the 'event_month' column.\n",
        "replace_number_values(# String 0.\n",
        "                      'event_month', \n",
        "                      \n",
        "                      # Integers 0-9.\n",
        "                      5, 0, 9, 4, 0, 7, 5, 8, 8, 4, \n",
        "                      \n",
        "                      # Integers 10-19.\n",
        "                      6, 7, 0, 0, 5, 6, 0, 4, 0, 0, \n",
        "                      \n",
        "                      # Integers 20-29.\n",
        "                      0, 6, 7, 4, 8, 0, 6, 0, 8, 0, \n",
        "                      \n",
        "                      # Integers 30-39.\n",
        "                      4, 0, 0, 0, 0, 7, 9, 4, 5, 9, \n",
        "                      \n",
        "                      # Integers 40-49.\n",
        "                      8, 8, 0, 0, 0, 0, 0, 6, 0, 4,\n",
        "                      \n",
        "                      # Integers 50-59.\n",
        "                      0, 0, 4, 8, 0, 9, 0, 0, 0, 6,\n",
        "\n",
        "                      # Integers 60-69.\n",
        "                      0, 0, 0, 0, 8, 6, 0, 0, 9, 0,\n",
        "                      \n",
        "                      # Integers 70-79.\n",
        "                      4, 0, 0, 0, 0, 0, 0, 0, 0, 8,\n",
        "                      \n",
        "                      # Integers 80-90.\n",
        "                      0, 9, 0, 7, 4, 0, 0, 8, 0, 6, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBMgd53xMYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Updating the 'company' colum.\n",
        "replace_number_values(# String 0.\n",
        "                      'company', \n",
        "                      \n",
        "                      # Integers 0-90.\n",
        "                      # Because all of the companies are assigned the same value, they can be listed together.\n",
        "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuBILjrFyGIB",
        "colab_type": "text"
      },
      "source": [
        "With all the columns updated, it'd be good to bring up the 'feature_engineered_df' to make sure it looks right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM11DEHix1z4",
        "colab_type": "code",
        "outputId": "40710ded-20d4-41b7-9db9-17f7fb3ba800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "feature_engineered_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "      <th>industry</th>\n",
              "      <th>nasdaq_listing</th>\n",
              "      <th>nasdaq_price</th>\n",
              "      <th>major_event</th>\n",
              "      <th>event_month</th>\n",
              "      <th>event_highlights</th>\n",
              "      <th>company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Cellular Telephones (Services)</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Cellular Telephones (Services)</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "      <td>115712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id   author_id  inbound  ... event_month event_highlights company\n",
              "0         1  sprintcare    False  ...           0              NaN       1\n",
              "1         2      115712     True  ...      115712           115712  115712\n",
              "2         3      115712     True  ...      115712           115712  115712\n",
              "3         4  sprintcare    False  ...           0              NaN       1\n",
              "4         5      115712     True  ...      115712           115712  115712\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYSMRkiC4Apv",
        "colab_type": "text"
      },
      "source": [
        "The table looks good! \n",
        "\n",
        "Now that the features are added, I'll move on to data cleaning.\n",
        "\n",
        "*3.3 Data Cleaning*\n",
        "\n",
        "This dataframe has string and integer data that needs to be cleaned, so a couple of different approaches will be needed for this step. To get this step started, I'll make a new dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qCs8qtGrQm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df = feature_engineered_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-YtaQBWMuCA",
        "colab_type": "text"
      },
      "source": [
        "*Cleaning the Numbers Data*\n",
        "\n",
        "The values in these columns need to be cleaned:\n",
        "\n",
        "* 'nasdaq_listing.'\n",
        "* 'nasdaq_price.'\n",
        "* 'major_event.'\n",
        "* 'event_month.'\n",
        "* 'company.'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt9HfI6kigpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The numbers columns can be cleaned with the same method, so I'll define a function for this step.\n",
        "def clean_numbers(string, int):\n",
        "    clean_df.loc[(clean_df[string] != int), string] = 0\n",
        "    return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsCIxUMLqnm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning 'nasdaq_listing'.\n",
        "clean_numbers('nasdaq_listing', 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK51TjWgwNw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning the 'nasdaq_price'.\n",
        "clean_numbers('nasdaq_price', 4-1146)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DycVbyhaqr9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning 'major_event'.\n",
        "clean_numbers('major_event', 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCRgkNBjwpiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning 'event_month'.\n",
        "clean_numbers('event_month', 4-9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w751NEsqyf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning 'company'.\n",
        "clean_numbers('company', 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bxdb62yrRK3",
        "colab_type": "text"
      },
      "source": [
        "*Language Parsing*\n",
        "\n",
        "With the numbers data taken care of, it's time to clean these columns:\n",
        "\n",
        "* 'text.'\n",
        "* 'industry.'\n",
        "* 'event_highlights.'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8yJbxim57XX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFE74kF557Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The 'clean_text' function will: make text lowercase, remove text in the square brackets, remove punctuation and words that have numbers.\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\'\\]', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = re.sub('[‘’“”…]', '', text)\n",
        "    return text\n",
        "\n",
        "round1 = lambda x: clean_text(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmYrFDUP57cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's take a look at the updated text\n",
        "clean_df['text'] = pd.DataFrame(clean_df['text'].apply(round1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GgF-Jrp6EFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df['industry'] = pd.DataFrame(clean_df['industry'].apply(round1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Beae-GDb3Y2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df['event_highlights'] = pd.DataFrame(clean_df['event_highlights'].apply(round1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_cBjbB19p8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df['created_at'] = pd.DataFrame(clean_df['created_at'].apply(round1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQRDA-pX9Wx7",
        "colab_type": "text"
      },
      "source": [
        "*Reviewing the Clean Dataframe*\n",
        "\n",
        "With the data cleaning and language parsing done, I'll look at the updated dataframe to make sure it looks right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUDZYNuw3Y5X",
        "colab_type": "code",
        "outputId": "214493a7-e2a4-48e8-951a-40e3b724d29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "clean_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "      <th>industry</th>\n",
              "      <th>nasdaq_listing</th>\n",
              "      <th>nasdaq_price</th>\n",
              "      <th>major_event</th>\n",
              "      <th>event_month</th>\n",
              "      <th>event_highlights</th>\n",
              "      <th>company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>tue oct</td>\n",
              "      <td>i understand i would like to assist you we wo...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>cellular telephones services</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>tue oct</td>\n",
              "      <td>sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>tue oct</td>\n",
              "      <td>sprintcare i have sent several private message...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>tue oct</td>\n",
              "      <td>please send us a private message so that we c...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>cellular telephones services</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>tue oct</td>\n",
              "      <td>sprintcare i did</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweet_id   author_id  inbound  ... event_month event_highlights company\n",
              "0         1  sprintcare    False  ...           0              nan       1\n",
              "1         2      115712     True  ...           0                        0\n",
              "2         3      115712     True  ...           0                        0\n",
              "3         4  sprintcare    False  ...           0              nan       1\n",
              "4         5      115712     True  ...           0                        0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMfqocIYYNcl",
        "colab_type": "code",
        "outputId": "16662d3c-a885-4892-e9ad-ecfa8271495e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clean_df['company'].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSB3d_UBemhM",
        "colab_type": "text"
      },
      "source": [
        "*Visualizing the Data*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9zEXHfWTOHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcs9WSskTOFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxbNwp6jTOCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKYzhMbHzpjm",
        "colab_type": "text"
      },
      "source": [
        "### Notes on NLP Analysis: \n",
        "\n",
        "- Look for Vader in the NLTK library. \n",
        "- They have a sentiment analyzer that was pre-trained and that can have its vocabularly tweaked.\n",
        "\n",
        "- Clustering - BoW, tf-idf. \n",
        "- Typically, instead of showing counts of each word, - words used across all the documents don't help you distinguish clusters.\n",
        "- tf-idf, which words are used in this document more than the average document. Words would tend to be useful for clustering. This is a good place to start. Clustering's based on ratios that says how\n",
        "- important each word is to the document. \n",
        "\n",
        "- Could try (only if tf-idf doesn't fly) LDA topic modeling. \n",
        "- LDA makes new features called topics. What are called topics are bunches of words that're used together. \n",
        "- In restaurants, got clusters of \"salad\", \"pizza\", etc. words. It didn't know anything about the food or words and built it based off how the words were used together in some documents and not others. \n",
        "- Topic modeling gives you a chance to see what people are talking about. A tweet could talk about more than one topic. It's a powerful technique, but may not need it for this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2KDIIwddPPV",
        "colab_type": "text"
      },
      "source": [
        "### 4. Analyzing Data with NLP (Supervised NLP)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JgllBpbdUq7",
        "colab_type": "code",
        "outputId": "04e850ab-0810-4d36-b509-fbcf7235f31e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import nltk\n",
        "\n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9YRBdVh43Ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrV_X8mEHdPJ",
        "colab_type": "text"
      },
      "source": [
        "*Retrying Bag of Words*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTC_Vb3k2DbI",
        "colab_type": "code",
        "outputId": "85245374-90eb-46db-a567-a3020808fa98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAHPxLezdz6O",
        "colab_type": "code",
        "outputId": "f490c29f-267b-401e-8a9e-fd5ba7b7904c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# You can check the target names (categories) and some data files by following commands.\n",
        "twenty_train.target_names #prints all the categories"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1zDyYnDQdGN",
        "colab_type": "code",
        "outputId": "f4ab5cc0-9a19-4b32-c783-ee727fb72fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Fl190PQdCx",
        "colab_type": "code",
        "outputId": "164a6986-7f4a-4f3b-abfb-9e352435eb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ-xzwiLQqFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzug4up9Qp9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
        "# The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n",
        "# We will be using the 'text_clf' going forward.\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
        "\n",
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaJMt-orQ0qS",
        "colab_type": "code",
        "outputId": "65e8a62f-440e-42bb-b104-7af8b0282c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Performance of NB Classifier\n",
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7738980350504514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IhRHKnNQ0li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfOlOwbHQ0f_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rJdEUUBQp3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_df = clean_df[['text', 'company']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr20rxd0Qc_a",
        "colab_type": "code",
        "outputId": "0c8c9461-4d01-4e8e-e4f8-5928548a9f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(sentences_df)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYPUkekQQc5t",
        "colab_type": "code",
        "outputId": "c164dec9-4cf2-4434-8dda-1e6b8913b609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjgU4lcEQc2V",
        "colab_type": "code",
        "outputId": "2495ec39-1800-498e-ea39-f3ee7dbc6e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Machine Learning\n",
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, sentences_df.company)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-4cb56e81f386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \"\"\"\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 2811774]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMQOwmpqQcxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1nu_cOhdz3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGzIOtPT2DdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybIHeIQ4Qs5m",
        "colab_type": "text"
      },
      "source": [
        "*Trying Another Approach to BoW Using BoW from the Function Defined Below, in the Topic Modeling Section*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXuScdA7DR0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = clean_df[['text', 'company']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6PZHA-3DZHD",
        "colab_type": "code",
        "outputId": "86206496-08e4-4536-c210-f0c15019340d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sentences.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i understand i would like to assist you we wo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sprintcare and how do you propose we do that</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sprintcare i have sent several private message...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>please send us a private message so that we c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sprintcare i did</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  company\n",
              "0   i understand i would like to assist you we wo...        1\n",
              "1       sprintcare and how do you propose we do that        0\n",
              "2  sprintcare i have sent several private message...        0\n",
              "3   please send us a private message so that we c...        1\n",
              "4                                   sprintcare i did        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qng9lVW1Acxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to create a list of the 2000 most common words.\n",
        "def bag_of_words(text):\n",
        "    \n",
        "    # Filter out punctuation and stop words.\n",
        "    allwords = [token.lemma_\n",
        "                for token in text]\n",
        "    \n",
        "    # Return the most common words.\n",
        "    return [item[0] for item in Counter(allwords).most_common(2000)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxWBKBVVAcul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates a data frame with features for each word in our common word set.\n",
        "# Each value is the count of the times the word appears in each sentence.\n",
        "\n",
        "# def bow_features(sentences, common_words):\n",
        "def bow_features(sentences):\n",
        "    \n",
        "    # Scaffold the data frame and initialize counts to zero.\n",
        "    df = pd.DataFrame()\n",
        "    df['text_sentence'] = sentences[0]\n",
        "    df['text_source'] = sentences[1]\n",
        "    \n",
        "    # Process each row, counting the occurrence of words in each sentence.\n",
        "    for i, sentence in enumerate(df['text_sentence']):\n",
        "        \n",
        "        # Convert the sentence to lemmas, then filter out punctuation,\n",
        "        # stop words, and uncommon words.\n",
        "        words = [token.lemma_\n",
        "                for token in sentence]\n",
        "        \n",
        "        # Populate the row with word counts.\n",
        "        for word in words:\n",
        "            df.loc[i, word] += 1\n",
        "        \n",
        "        # This counter is just to make sure the kernel didn't hang.\n",
        "        if i % 50 == 0:\n",
        "            print(\"Processing row {}\".format(i))\n",
        "            \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb9w6WIVAcsN",
        "colab_type": "code",
        "outputId": "cf90c98d-5336-4712-93d5-be5f7f81ea6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Set up the bags.\n",
        "twitter_words = bag_of_words(sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-e5f6da865c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtwitter_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-90-09eae163cee7>\u001b[0m in \u001b[0;36mbag_of_words\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Filter out punctuation and stop words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     allwords = [token.lemma_\n\u001b[0;32m----> 5\u001b[0;31m                 for token in text]\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Return the most common words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-09eae163cee7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Filter out punctuation and stop words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     allwords = [token.lemma_\n\u001b[0;32m----> 5\u001b[0;31m                 for token in text]\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Return the most common words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'lemma_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFppf96uAj21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izz10AwNAjzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jk94v9OAcoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AucoaURtQsSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# bow_corpus\n",
        "\n",
        "rfc = ensemble.RandomForestClassifier()\n",
        "Y = word_counts['text_source']\n",
        "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.4,\n",
        "                                                    random_state=0)\n",
        "train = rfc.fit(X_train, y_train)\n",
        "\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJyg4J32dP-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnCs4dYiQsgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBHc9WR1Qse4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWyGlw8iQscf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov209oftQsa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJAbQglWdU_U",
        "colab_type": "text"
      },
      "source": [
        "### 5. Topic Modeling (Unsupervised NLP)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBZFCgbdXJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQoaX3PW7COp",
        "colab_type": "code",
        "outputId": "5746ed26-12e3-43f7-af5a-d66966415527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgtcDuANEGHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKOee28BdXMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write a function to perform the pre processing steps on the entire dataset\n",
        "\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Tokenize and lemmatize\n",
        "def preprocess(text):\n",
        "    result=[]\n",
        "    for token in gensim.utils.simple_preprocess(text) :\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "            \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWIJTjWpDnOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# processed_text = twitter_df['text'].sample(n=50000, random_state=1)\n",
        "# print(processed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYMy0VnkDVr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_docs = []\n",
        "\n",
        "for doc in twitter_df['text'].sample(n=50000, random_state=1):\n",
        "    processed_docs.append(preprocess(doc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_l6zv56DVuh",
        "colab_type": "code",
        "outputId": "b1691c54-3ce8-4071-e30a-5ce05dabe7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(processed_docs[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['atviassist'], ['applesupport', 'iphon']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BSCI7cQDVx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary from 'processed_docs' containing the number of times a word appears \n",
        "# in the training set using gensim.corpora.Dictionary and call it 'dictionary'\n",
        "\n",
        "dictionary = gensim.corpora.Dictionary(processed_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bb8aOlSGItw",
        "colab_type": "code",
        "outputId": "724120a1-183b-49aa-cdf4-cb2236d1b514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Checking dictionary created\n",
        "\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 atviassist\n",
            "1 applesupport\n",
            "2 iphon\n",
            "3 americanair\n",
            "4 dumb\n",
            "5 know\n",
            "6 store\n",
            "7 think\n",
            "8 pain\n",
            "9 info\n",
            "10 send\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGdPt5EGbJf9",
        "colab_type": "text"
      },
      "source": [
        "- Gensim filter_extremes\n",
        "\n",
        "- filter_extremes(no_below=5, no_above=0.5, keep_n=100000)\n",
        "\n",
        "- Filter out tokens that appear in:\n",
        "- less than no_below documents (absolute number) or\n",
        "- more than no_above documents (fraction of total corpus size, not absolute number).\n",
        "- after (1) and (2), keep only the first keep_n most frequent tokens (or keep all if None)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhV5GAPPGbhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OPTIONAL STEP\n",
        "# Remove very rare and very common words:\n",
        "# - words appearing less than 15 times\n",
        "# - words appearing in more than 10% of all documents\n",
        "\n",
        "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n= 100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA6mTIFRbaFU",
        "colab_type": "text"
      },
      "source": [
        "- Gensim doc2bow\n",
        "\n",
        "- doc2bow(document)\n",
        "\n",
        "- Convert document (a list of words) into the bag-of-words format = list of (token_id, token_count) 2-tuples. Each word is assumed to be a tokenized and normalized string (either unicode or utf8-encoded). \n",
        "- No further preprocessing is done on the words in document; apply tokenization, stemming etc. before calling this method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFOMeyX3GbmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
        "# words and how many times those words appear. Save this to 'bow_corpus'\n",
        "\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g2cDRvrGybq",
        "colab_type": "code",
        "outputId": "01311c23-aeae-4491-a811-a88e95d9936d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Preview BOW for our sample preprocessed document\n",
        "\n",
        "document_num = 20\n",
        "bow_doc_x = bow_corpus[document_num]\n",
        "\n",
        "for i in range(len(bow_doc_x)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
        "                                                     dictionary[bow_doc_x[i][0]], \n",
        "                                                     bow_doc_x[i][1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 86 (\"kind\") appears 1 time.\n",
            "Word 87 (\"respons\") appears 1 time.\n",
            "Word 88 (\"uber_support\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7IxwiNTHKs0",
        "colab_type": "text"
      },
      "source": [
        "We are going for 10 topics in the document corpus.\n",
        "\n",
        "We will be running LDA using all CPU cores to parallelize and speed up model training.\n",
        "\n",
        "Some of the parameters we will be tweaking are:\n",
        "\n",
        "num_topics is the number of requested latent topics to be extracted from the training corpus.\n",
        "id2word is a mapping from word ids (integers) to words (strings). It is used to determine the vocabulary size, as well as for debugging and topic printing.\n",
        "workers is the number of extra processes to use for parallelization. Uses all available cores by default.\n",
        "alpha and eta are hyperparameters that affect sparsity of the document-topic (theta) and topic-word (lambda) distributions. We will let these be the default values for now(default value is 1/num_topics)\n",
        "\n",
        "Alpha is the per document topic distribution.\n",
        "\n",
        "High alpha: Every document has a mixture of all topics(documents appear similar to each other).\n",
        "Low alpha: Every document has a mixture of very few topics\n",
        "Eta is the per topic word distribution.\n",
        "\n",
        "High eta: Each topic has a mixture of most words(topics appear similar to each other).\n",
        "Low eta: Each topic has a mixture of few words.\n",
        "passes is the number of training passes through the corpus. For example, if the training corpus has 50,000 documents, chunksize is 10,000, passes is 2, then online training is done in 10 updates:\n",
        "\n",
        "- 1 documents 0-9,999\n",
        "- 2 documents 10,000-19,999\n",
        "- 3 documents 20,000-29,999\n",
        "- 4 documents 30,000-39,999\n",
        "- 5 documents 40,000-49,999\n",
        "- 6 documents 0-9,999\n",
        "- 7 documents 10,000-19,999\n",
        "- 8 documents 20,000-29,999\n",
        "- 9 documents 30,000-39,999\n",
        "- 10 documents 40,000-49,999"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjnovHk6G4uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LDA mono-core -- fallback code in case LdaMulticore throws an error on your machine\n",
        "# lda_model = gensim.models.LdaModel(bow_corpus, \n",
        "#                                    num_topics = 10, \n",
        "#                                    id2word = dictionary,                                    \n",
        "#                                    passes = 50)\n",
        "\n",
        "# LDA multicore \n",
        "'''\n",
        "Train your lda model using gensim.models.LdaMulticore and save it to 'lda_model'\n",
        "'''\n",
        "# TODO\n",
        "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
        "                                   num_topics = 8, \n",
        "                                   id2word = dictionary,                                    \n",
        "                                   passes = 10,\n",
        "                                   workers = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SafqekPkHD4Z",
        "colab_type": "code",
        "outputId": "b541053e-b970-41ed-87bb-2044ca262683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# For each topic, we will explore the words occuring in that topic and its relative weight\n",
        "\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.042*\"flight\" + 0.025*\"americanair\" + 0.024*\"delta\" + 0.019*\"book\" + 0.019*\"virgintrain\" + 0.017*\"southwestair\" + 0.016*\"british_airway\" + 0.015*\"hour\" + 0.014*\"time\" + 0.013*\"travel\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.055*\"send\" + 0.049*\"look\" + 0.038*\"number\" + 0.037*\"assist\" + 0.035*\"account\" + 0.034*\"address\" + 0.032*\"email\" + 0.030*\"sorri\" + 0.026*\"detail\" + 0.024*\"issu\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.026*\"devic\" + 0.023*\"know\" + 0.020*\"work\" + 0.018*\"version\" + 0.017*\"start\" + 0.015*\"gdrqu\" + 0.013*\"like\" + 0.013*\"want\" + 0.012*\"upgrad\" + 0.012*\"get\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.026*\"servic\" + 0.019*\"time\" + 0.018*\"custom\" + 0.018*\"tesco\" + 0.017*\"uber_support\" + 0.015*\"go\" + 0.014*\"issu\" + 0.013*\"work\" + 0.012*\"charg\" + 0.012*\"phone\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.032*\"store\" + 0.023*\"card\" + 0.018*\"account\" + 0.017*\"xboxsupport\" + 0.017*\"option\" + 0.015*\"onlin\" + 0.014*\"purchas\" + 0.012*\"check\" + 0.012*\"tri\" + 0.012*\"websit\"\n",
            "\n",
            "\n",
            "Topic: 5 \n",
            "Words: 0.047*\"team\" + 0.031*\"sorri\" + 0.027*\"know\" + 0.026*\"hear\" + 0.023*\"sure\" + 0.018*\"support\" + 0.018*\"feedback\" + 0.017*\"soon\" + 0.017*\"hope\" + 0.016*\"great\"\n",
            "\n",
            "\n",
            "Topic: 6 \n",
            "Words: 0.063*\"amazonhelp\" + 0.059*\"order\" + 0.027*\"deliveri\" + 0.025*\"receiv\" + 0.020*\"amazon\" + 0.020*\"delay\" + 0.018*\"train\" + 0.018*\"deliv\" + 0.017*\"packag\" + 0.015*\"sorri\"\n",
            "\n",
            "\n",
            "Topic: 7 \n",
            "Words: 0.060*\"applesupport\" + 0.040*\"updat\" + 0.025*\"iphon\" + 0.022*\"free\" + 0.020*\"phone\" + 0.019*\"spotifycar\" + 0.015*\"problem\" + 0.013*\"chipotletweet\" + 0.013*\"feel\" + 0.012*\"tri\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd3E4mGaRPE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take the top five words(ish) for each category. Using expertise, label cateogry in interesting ways, that'll be your topic name.\n",
        "# If words are too general, add them to your stop words and see what shows up.\n",
        "# Goal: It'd be nice for the top few topics to be clean and explainable.\n",
        "\n",
        "# LDA gives 1. topics that are represented. 2. for each of the documents you gave it, it'll tell you how strong it is in each of the topics. Look for the document weightings for each topic.\n",
        "# 2. Get a matrix that has a column for each topic and row for each document. Might have more than one topic that's relatively high (or there could be one).  \n",
        "# 2. Then you can look on a per company basis and see what the top topics that companies are tweeting about."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L9zb5w63tZi",
        "colab_type": "text"
      },
      "source": [
        "### 6. Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRGyuYpU3wJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiYU71viVZlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_text_df = clean_df[['text', 'company', 'author_id']].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6l8_PemYiLl",
        "colab_type": "code",
        "outputId": "ba3c5241-d2ff-4c8d-a88a-d740af8172dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_text_df['company'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4lrKXi1Y_8v",
        "colab": {}
      },
      "source": [
        "sample_text_df = sample_text_df.sample(n=50000, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on7maeS_XxLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_pol(review):\n",
        "    return TextBlob(review).sentiment.polarity\n",
        "\n",
        "sample_text_df['polarity'] = sample_text_df['text'].apply(find_pol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbOfuDv0XxQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_pol(subjectivity):\n",
        "    return TextBlob(subjectivity).sentiment.subjectivity\n",
        "\n",
        "sample_text_df['subjectivity'] = sample_text_df['text'].apply(find_pol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyJzpG2TU9aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Don't re-run LDA - need to aggregate documents according to the story you want to tell.\n",
        "# Could talk about what's happening on a company level, overall company's topics vs. non-company topics. Groupby() can be useful here, with an aggregation function like describe(), avg() or mean()."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVA2FeiRY9ss",
        "colab_type": "code",
        "outputId": "68426f4f-95c8-4764-a579-ac3a91f6b635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_text_df['company'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nYLgbijZwKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_text_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twjp1SzSXxVc",
        "colab_type": "code",
        "outputId": "98da930c-1e05-4447-9046-367e132bd409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sample_text_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>company</th>\n",
              "      <th>author_id</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2360834</th>\n",
              "      <td>atviassist pls fix hqs</td>\n",
              "      <td>0</td>\n",
              "      <td>719820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375495</th>\n",
              "      <td>applesupport iphone  with  ios</td>\n",
              "      <td>0</td>\n",
              "      <td>216966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177509</th>\n",
              "      <td>either im dumb bc i dont know how to use the a...</td>\n",
              "      <td>0</td>\n",
              "      <td>165872</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497308</th>\n",
              "      <td>its such a pain mine is doing it too</td>\n",
              "      <td>0</td>\n",
              "      <td>502403</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2179157</th>\n",
              "      <td>sorry we got it wrong could you send us a dm ...</td>\n",
              "      <td>0</td>\n",
              "      <td>KFC_UKI_Help</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text  ...  subjectivity\n",
              "2360834                            atviassist pls fix hqs   ...           0.0\n",
              "375495                      applesupport iphone  with  ios  ...           0.0\n",
              "177509   either im dumb bc i dont know how to use the a...  ...           0.5\n",
              "1497308               its such a pain mine is doing it too  ...           0.5\n",
              "2179157   sorry we got it wrong could you send us a dm ...  ...           0.8\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKA5p2npQWBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Two-dimensional scatterplot to show where each company fits on the plot.\n",
        "# What's their average on those two dimensions.\n",
        "# Some will be mildly positive, or the other end and be negative.\n",
        "# Look at example tweets that are at the high and low ranges to generalize what the scores mean."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpVKzpcGVJV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_text_df['company'] = sample_text_df['company'] != 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTVXjRTYZFlt",
        "colab_type": "code",
        "outputId": "091e269b-0eb0-4b68-ac76-d073bc88d605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_text_df['company'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv2nff9vVJmC",
        "colab_type": "code",
        "outputId": "fad98b26-97f2-4895-e368-19d2b05b265a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sample_text_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>company</th>\n",
              "      <th>author_id</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2360834</th>\n",
              "      <td>atviassist pls fix hqs</td>\n",
              "      <td>True</td>\n",
              "      <td>719820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375495</th>\n",
              "      <td>applesupport iphone  with  ios</td>\n",
              "      <td>True</td>\n",
              "      <td>216966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177509</th>\n",
              "      <td>either im dumb bc i dont know how to use the a...</td>\n",
              "      <td>True</td>\n",
              "      <td>165872</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497308</th>\n",
              "      <td>its such a pain mine is doing it too</td>\n",
              "      <td>True</td>\n",
              "      <td>502403</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2179157</th>\n",
              "      <td>sorry we got it wrong could you send us a dm ...</td>\n",
              "      <td>True</td>\n",
              "      <td>KFC_UKI_Help</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text  ...  subjectivity\n",
              "2360834                            atviassist pls fix hqs   ...           0.0\n",
              "375495                      applesupport iphone  with  ios  ...           0.0\n",
              "177509   either im dumb bc i dont know how to use the a...  ...           0.5\n",
              "1497308               its such a pain mine is doing it too  ...           0.5\n",
              "2179157   sorry we got it wrong could you send us a dm ...  ...           0.8\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhFNCJDRVJ3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJq00b6kVJiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dYsqg1HdXgs",
        "colab_type": "text"
      },
      "source": [
        "### 6. Key Takeaways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVA5DsetdZ6M",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr8cstRPdZ8r",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9jysgBCdaZU",
        "colab_type": "text"
      },
      "source": [
        "### 7. Next Steps\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PPi2khpeOZN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uEzzb8KeOc8",
        "colab_type": "text"
      },
      "source": [
        "- Use clustering to analyze patterns in the companies.\n",
        "- Look at things by industry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GQIBK3qyyVP",
        "colab_type": "text"
      },
      "source": [
        "### 8. Resources\n",
        "\n",
        "This is the list of resources that were used for this analysis:\n",
        "\n",
        "1. [Google News](https://news.google.com/?hl=en-US&gl=US&ceid=US:en).\n",
        "2. [Salesgenie.com](https://www.salesgenie.com/).\n",
        "3. [Steinmetz, Katy](https://time.com/4894182/twitter-company-complaints/). Time - Tech. \"Does Tweeting at Companies Really Work?\"\n",
        "4. [US Chamber of Commerce](https://www.uschamber.com/about/about-the-us-chamber/frequently-asked-questions#3). \"Frequently Asked Questions.\"\n",
        "5. [Yahoo! Finance](https://finance.yahoo.com/).\n",
        "\n",
        "- LDA resource: https://github.com/priya-dwivedi/Deep-Learning/blob/master/topic_modeling/LDA_Newsgroup.ipynb\n",
        "- Additional LDA resource: https://towardsdatascience.com/nlp-extracting-the-main-topics-from-your-dataset-using-lda-in-minutes-21486f5aa925\n",
        "\n",
        "- Kaggle dataset: https://www.kaggle.com/thoughtvector/customer-support-on-twitter/data\n",
        "\n",
        "- Sentiment analysis: https://github.com/adashofdata/nlp-in-python-tutorial/blob/master/3-Sentiment-Analysis.ipynb\n",
        "\n",
        "- Sentiment Polarity: https://stackabuse.com/python-for-nlp-introduction-to-the-textblob-library/\n",
        "- Sentiment Analysis from YouTube series: https://github.com/adashofdata/nlp-in-python-tutorial/blob/master/3-Sentiment-Analysis.ipynb\n",
        "\n",
        "- Uploading content to Google Colab: https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSytiR0hnA56",
        "colab_type": "text"
      },
      "source": [
        "# 9. Appendix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzrCVyq4AmBC",
        "colab_type": "text"
      },
      "source": [
        "For your reference, here's the list of non-US companies that were in the dataframe and which industry they were assigned to:\n",
        "\n",
        "1. Aldi UK, Grocers - Retail.\n",
        "2. Argos, Retail.\n",
        "3. Dollar Shave Club, Retail.\n",
        "4. Glo, Cellular Telephones (Services).\n",
        "5. Great Western Railway, Commuter & Passenger Rail Service.\n",
        "6. Greggs, Restaurants.\n",
        "7. InterContinental Hotel Group, Hotel & Motel Management.\n",
        "8. London Midland, Commuter & Passenger Rail Service.\n",
        "9. Marks and Spencer, Grocers - Retail.\n",
        "10. Morrisons, Grocers - Retail.\n",
        "11. National Rail, Commuter & Passenger Rail Service.\n",
        "12. OPPO Care India, Cellular Telephones (Services).\n",
        "13. Pearson, Education.\n",
        "14. PlayStation, Video Games - Manufacturer.\n",
        "15. Royal Bank of Canada, Banks.\n",
        "16. Sainsburys, Grocers - Retail.\n",
        "17. Size?, Retail.\n",
        "18. SoundCloud, Radio Stations & Broadcasting Companies.\n",
        "19. Spotify, Radio Stations & Broadcasting Companies.\n",
        "20. Tesco, Grocers - Retail.\n",
        "21. Tigo Ghana, Cellular Telephones (Services).\n",
        "22. Transport for London, Commuter & Passenger Rail Service.\n",
        "23. Virgin America, Airline Companies.\n",
        "24. Virgin Atlantic, Airline Companies.\n",
        "25. Virgin Mobile USA, Cellular Telephones (Services).\n",
        "26. Virgin Money, Banks.\n",
        "27. Virgin Trains, Commuter & Passenger Rail Service.\n",
        "\n"
      ]
    }
  ]
}